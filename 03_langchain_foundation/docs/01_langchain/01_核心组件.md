# LangChain (Python) - 核心组件学习笔记

## 概述

LangChain 是一个开源框架，专为构建基于大语言模型（LLM）的应用而设计。它提供了预构建的代理架构和与任何模型或工具的集成能力，使开发者能够快速构建智能应用。

### 核心特点

- **分层架构**：LangChain 构建在 LangGraph 之上，LangGraph 是低级代理编排框架和运行时
- **统一接口**：为不同的模型提供商（OpenAI、Anthropic、Google 等）提供标准化接口
- **快速开发**：可以用不到 10 行代码连接模型和工具
- **调试工具**：通过 LangSmith 提供可视化追踪和执行路径分析

### 适用场景

**推荐使用 LangChain 的情况：**
- 快速构建代理和自主应用
- 需要灵活的上下文工程
- 需要预构建的代理架构

**选择 LangGraph 的情况：**
- 需要确定性和代理工作流结合
- 需要深度自定义和精确的延迟控制

---

## 1. Overview & Quickstart

### 核心概念

LangChain 的核心目标是简化 LLM 应用开发流程，通过提供：
1. **模型集成**：支持多个 AI 提供商的统一接口
2. **代理创建**：将模型与工具连接的简化框架
3. **标准化接口**：避免供应商锁定
4. **持久化执行**：支持流处理和人工干预

### 快速开始

#### 安装步骤

```bash
# 1. 安装 LangChain 包
pip install langchain langchain-anthropic

# 2. 设置 API 密钥（环境变量）
export ANTHROPIC_API_KEY="your-api-key-here"
```

#### 最小化示例

```python
from langchain.chat_models import init_chat_model
from langchain.tools import tool

# 定义工具
@tool
def get_weather(location: str) -> str:
    """获取指定地点的天气信息"""
    return f"{location} 的天气晴朗，气温 22°C"

# 初始化模型
model = init_chat_model("claude-sonnet-4-5-20250929")

# 绑定工具
model_with_tools = model.bind_tools([get_weather])

# 调用模型
response = model_with_tools.invoke("北京的天气怎么样？")
print(response)
```

### 生产级代理的六个步骤

#### 步骤 1：定义系统提示

```python
system_prompt = """你是一个专业的天气助手。
你的任务是：
- 提供准确的天气信息
- 使用友好、专业的语气
- 如果不确定，请明确告知用户"""
```

#### 步骤 2：创建工具

```python
from langchain.tools import tool
import requests

@tool
def get_weather(location: str) -> str:
    """获取指定城市的实时天气信息

    Args:
        location: 城市名称（如：北京、上海）

    Returns:
        包含温度、天气状况的字符串
    """
    # 实际应该调用真实的天气 API
    return f"{location} 的天气晴朗，气温 22°C，湿度 60%"

@tool
def get_forecast(location: str, days: int = 3) -> str:
    """获取未来几天的天气预报

    Args:
        location: 城市名称
        days: 预报天数（1-7天）

    Returns:
        天气预报信息
    """
    return f"{location} 未来{days}天：晴转多云，气温 18-25°C"
```

#### 步骤 3：配置模型

```python
from langchain.chat_models import init_chat_model

model = init_chat_model(
    "claude-sonnet-4-5-20250929",
    temperature=0.7,        # 控制输出随机性
    timeout=30,             # 请求超时时间（秒）
    max_tokens=1000,        # 最大输出令牌数
    max_retries=2           # 失败重试次数
)
```

#### 步骤 4：定义响应格式

```python
from pydantic import BaseModel, Field

class WeatherResponse(BaseModel):
    """天气响应的结构化输出"""
    location: str = Field(..., description="查询的城市名称")
    temperature: float = Field(..., description="温度（摄氏度）")
    condition: str = Field(..., description="天气状况（如：晴、多云、雨）")
    humidity: int = Field(..., description="湿度（百分比）")

# 应用结构化输出
model_with_structure = model.with_structured_output(WeatherResponse)
```

#### 步骤 5：添加记忆管理

```python
from langgraph.checkpoint.memory import InMemorySaver

# 开发环境使用内存存储
memory = InMemorySaver()

# 生产环境使用持久化存储
# from langgraph.checkpoint.postgres import PostgresSaver
# memory = PostgresSaver(connection_string="postgresql://...")
```

#### 步骤 6：创建并运行代理

```python
from langchain.agents import create_agent

# 创建代理
agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[get_weather, get_forecast],
    system_prompt=system_prompt,
    checkpointer=memory
)

# 运行代理
config = {"thread_id": "user_123"}  # 维持会话一致性

result = agent.invoke({
    "messages": [{"role": "user", "content": "北京今天天气怎么样？"}]
}, config=config)

print(result)

# 继续对话（同一 thread_id）
result2 = agent.invoke({
    "messages": [{"role": "user", "content": "那未来三天呢？"}]
}, config=config)
```

---

## 2. Agents (代理)

### 核心概念

代理（Agent）是将语言模型与工具相结合的系统，能够：
- **推理任务**：理解用户意图，分解复杂问题
- **决定工具**：选择合适的工具来完成任务
- **迭代执行**：通过多次推理-行动循环寻求解决方案

#### ReAct 模式

代理遵循 **ReAct（推理 + 行动）** 模式：

```
用户问题 → 推理步骤 → 工具调用 → 观察结果 → 推理步骤 → 工具调用 → ... → 最终答案
```

### 核心组件

#### 1. 模型（推理引擎）

**静态模型配置**（推荐用于一般场景）：

```python
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4",
    tools=[search_tool, calculator_tool]
)
```

**动态模型配置**（根据运行时状态选择模型）：

```python
from langchain.agents import wrap_model_call
from langchain.chat_models import init_chat_model

@wrap_model_call
def dynamic_model(state, context):
    """根据对话复杂度选择模型"""
    message_count = len(state["messages"])

    if message_count > 10:
        # 长对话使用更强大的模型
        return init_chat_model("gpt-4")
    else:
        # 短对话使用更快的模型
        return init_chat_model("gpt-3.5-turbo")

agent = create_agent(
    model=dynamic_model,
    tools=[search_tool]
)
```

#### 2. 工具定义

工具赋予代理采取行动的能力：

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """在客户数据库中搜索信息

    Args:
        query: 搜索查询字符串
        limit: 返回结果的最大数量

    Returns:
        搜索结果的 JSON 字符串
    """
    # 实际的数据库查询逻辑
    results = {"count": 5, "results": [...]}
    return str(results)

@tool
def send_email(to: str, subject: str, body: str) -> str:
    """发送电子邮件

    Args:
        to: 收件人邮箱地址
        subject: 邮件主题
        body: 邮件正文

    Returns:
        发送状态信息
    """
    # 实际的邮件发送逻辑
    return f"邮件已发送至 {to}"
```

**工具特性：**
- 支持多个工具按顺序调用
- 支持并行执行多个工具
- 内置错误处理和重试逻辑
- 支持动态工具选择

#### 3. 系统提示

通过系统提示塑造代理行为：

```python
from langchain_core.messages import SystemMessage

# 方式 1：简单字符串
system_prompt = "你是一个专业的客户支持助手，始终保持礼貌和耐心。"

agent = create_agent(
    model="gpt-4",
    tools=[search_tool],
    system_prompt=system_prompt
)

# 方式 2：使用 SystemMessage 对象（支持高级特性如提示缓存）
system_message = SystemMessage(
    content="你是一个专业的客户支持助手，始终保持礼貌和耐心。",
    additional_kwargs={
        "cache_control": {"type": "ephemeral"}  # Anthropic 提示缓存
    }
)

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[search_tool],
    system_prompt=system_message
)
```

### 使用方法

#### 基础调用

```python
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4",
    tools=[search_tool, calculator_tool],
    system_prompt="你是一个有用的助手"
)

# 调用代理
result = agent.invoke({
    "messages": [{"role": "user", "content": "帮我搜索 Python 教程"}]
})

print(result["messages"][-1]["content"])
```

#### 流式输出

```python
# 流式输出代理执行进度
for chunk in agent.stream({
    "messages": [{"role": "user", "content": "分析这个数据集"}]
}, stream_mode="updates"):
    print(chunk)
```

### 高级功能

#### 1. 结构化输出

```python
from langchain.agents import create_agent, ProviderStrategy
from pydantic import BaseModel, Field

class AnalysisResult(BaseModel):
    summary: str = Field(..., description="分析摘要")
    key_findings: list[str] = Field(..., description="关键发现")
    confidence: float = Field(..., description="置信度 0-1")

agent = create_agent(
    model="gpt-4",
    tools=[analysis_tool],
    structured_output_strategy=ProviderStrategy(
        schema=AnalysisResult,
        strict=True
    )
)
```

#### 2. 内存管理

代理通过消息状态自动维护对话历史：

```python
from langgraph.checkpoint.memory import InMemorySaver

agent = create_agent(
    model="gpt-4",
    tools=[search_tool],
    checkpointer=InMemorySaver()
)

# 第一轮对话
config = {"thread_id": "conversation_1"}
agent.invoke({
    "messages": [{"role": "user", "content": "我的名字是张三"}]
}, config=config)

# 第二轮对话（代理会记住之前的对话）
agent.invoke({
    "messages": [{"role": "user", "content": "我叫什么名字？"}]
}, config=config)
```

#### 3. 自定义状态

```python
from typing import TypedDict
from langchain.agents import create_agent

class CustomState(TypedDict):
    messages: list
    user_id: str
    preference: str
    request_count: int

agent = create_agent(
    model="gpt-4",
    tools=[personalized_tool],
    state_schema=CustomState
)

# 使用自定义状态
result = agent.invoke({
    "messages": [{"role": "user", "content": "推荐一本书"}],
    "user_id": "user_123",
    "preference": "科幻",
    "request_count": 0
})
```

### 代码示例

#### 完整的客户支持代理

```python
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.checkpoint.memory import InMemorySaver
import json

# 定义工具
@tool
def search_orders(customer_id: str) -> str:
    """搜索客户的订单历史"""
    orders = [
        {"order_id": "ORD001", "status": "已发货", "total": 299.99},
        {"order_id": "ORD002", "status": "处理中", "total": 159.50}
    ]
    return json.dumps(orders, ensure_ascii=False)

@tool
def check_inventory(product_id: str) -> str:
    """检查产品库存状态"""
    inventory = {"product_id": product_id, "stock": 15, "available": True}
    return json.dumps(inventory, ensure_ascii=False)

@tool
def create_ticket(issue: str, priority: str = "normal") -> str:
    """创建客户支持工单

    Args:
        issue: 问题描述
        priority: 优先级（low, normal, high）
    """
    ticket_id = f"TKT-{hash(issue) % 10000:04d}"
    return f"工单已创建：{ticket_id}，优先级：{priority}"

# 创建代理
system_prompt = """你是一个专业的客户支持代理。你的职责包括：

1. 查询订单状态和历史
2. 检查产品库存
3. 为复杂问题创建支持工单
4. 始终保持礼貌、耐心和专业

在回答问题前，确保收集了必要的信息（如客户 ID、产品 ID 等）。"""

agent = create_agent(
    model="gpt-4",
    tools=[search_orders, check_inventory, create_ticket],
    system_prompt=system_prompt,
    checkpointer=InMemorySaver()
)

# 使用代理
config = {"thread_id": "customer_001"}

# 第一次交互
result1 = agent.invoke({
    "messages": [{"role": "user", "content": "我的客户 ID 是 CUST123，想查看我的订单"}]
}, config=config)

print("助手:", result1["messages"][-1]["content"])

# 第二次交互
result2 = agent.invoke({
    "messages": [{"role": "user", "content": "ORD002 这个订单什么时候能发货？"}]
}, config=config)

print("助手:", result2["messages"][-1]["content"])
```

### 最佳实践

1. **明确的工具描述**：确保工具的 docstring 清晰描述功能和参数，帮助模型正确使用
2. **合理的系统提示**：明确代理的角色、能力范围和行为准则
3. **错误处理**：在工具中实现适当的错误处理和验证
4. **使用持久化存储**：生产环境中使用数据库支持的 checkpointer
5. **监控和调试**：使用 LangSmith 跟踪代理执行过程
6. **控制上下文长度**：使用消息修剪策略避免超出模型上下文窗口

---

## 3. Models (模型)

### 核心概念

LangChain 中的模型是 AI 推理引擎，能够解释和生成文本，足够灵活应对多种任务，包括：
- 内容写作
- 语言翻译
- 文本摘要
- 问答系统

### 四大核心能力

1. **工具调用（Tool Calling）**
   - 调用外部工具（数据库查询、API 调用）
   - 在响应中使用工具执行结果

2. **结构化输出（Structured Output）**
   - 约束模型响应遵循定义格式
   - 返回 JSON 对象、Pydantic 模型等

3. **多模态处理（Multimodal）**
   - 处理图像、音频、视频等非文本数据
   - 返回多种格式的内容

4. **推理能力（Reasoning）**
   - 执行多步推理得出结论
   - 处理复杂的逻辑问题

### 使用方法

#### 1. 初始化模型

```python
from langchain.chat_models import init_chat_model

# OpenAI 模型
model = init_chat_model("gpt-4")

# Anthropic 模型
model = init_chat_model("claude-sonnet-4-5-20250929")

# Google 模型
model = init_chat_model("gemini-pro")

# Azure OpenAI
model = init_chat_model(
    "gpt-4",
    model_provider="azure_openai",
    azure_endpoint="https://your-endpoint.openai.azure.com/"
)
```

#### 2. 三种调用方法

##### Invoke（单次调用）

返回单个完整响应，适合标准文本生成：

```python
from langchain_core.messages import HumanMessage

response = model.invoke([
    HumanMessage(content="解释什么是量子计算")
])

print(response.content)
```

##### Stream（流式输出）

实时流式输出，适合长文本逐步显示：

```python
for chunk in model.stream([
    HumanMessage(content="写一篇关于人工智能的文章")
]):
    print(chunk.content, end="", flush=True)
```

##### Batch（批量处理）

并行处理多个请求，提高效率：

```python
messages_list = [
    [HumanMessage(content="翻译：Hello")],
    [HumanMessage(content="翻译：Goodbye")],
    [HumanMessage(content="翻译：Thank you")]
]

responses = model.batch(messages_list)

for response in responses:
    print(response.content)
```

#### 3. 关键参数配置

```python
model = init_chat_model(
    "gpt-4",
    temperature=0.7,      # 控制输出随机性（0.0-2.0，越高越创意）
    max_tokens=1000,      # 限制响应长度
    timeout=30,           # 请求超时时间（秒）
    max_retries=2,        # 失败重试次数
    streaming=True        # 启用流式输出
)
```

**参数说明：**
- `temperature`: 0 表示确定性输出，2 表示最大随机性
- `max_tokens`: 限制生成的最大令牌数
- `timeout`: API 请求超时时间
- `max_retries`: 网络失败时的重试次数

### 代码示例

#### 1. 工具调用示例

```python
from langchain.chat_models import init_chat_model
from langchain.tools import tool
from langchain_core.messages import HumanMessage

# 定义工具
@tool
def get_weather(location: str) -> str:
    """获取指定地点的天气信息"""
    # 模拟天气数据
    weather_data = {
        "北京": "晴天，22°C",
        "上海": "多云，25°C",
        "广州": "小雨，28°C"
    }
    return weather_data.get(location, "未知地点")

@tool
def calculate(expression: str) -> str:
    """计算数学表达式"""
    try:
        result = eval(expression)
        return str(result)
    except Exception as e:
        return f"计算错误: {str(e)}"

# 初始化模型并绑定工具
model = init_chat_model("gpt-4")
model_with_tools = model.bind_tools([get_weather, calculate])

# 调用模型
response = model_with_tools.invoke([
    HumanMessage(content="北京的天气怎么样？")
])

print("模型响应:", response)
print("工具调用:", response.tool_calls)

# 如果有工具调用，执行工具
if response.tool_calls:
    tool_call = response.tool_calls[0]
    print(f"调用工具: {tool_call['name']}")
    print(f"参数: {tool_call['args']}")
```

#### 2. 结构化输出示例

```python
from pydantic import BaseModel, Field
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage

# 定义输出结构
class Movie(BaseModel):
    """电影信息"""
    title: str = Field(..., description="电影标题")
    year: int = Field(..., description="发行年份")
    director: str = Field(..., description="导演姓名")
    genre: list[str] = Field(..., description="电影类型列表")
    rating: float = Field(..., description="评分（0-10）")

# 配置模型使用结构化输出
model = init_chat_model("gpt-4")
model_with_structure = model.with_structured_output(Movie)

# 调用模型
response = model_with_structure.invoke([
    HumanMessage(content="介绍一下电影《盗梦空间》")
])

# 响应是一个 Pydantic 模型实例
print(f"标题: {response.title}")
print(f"年份: {response.year}")
print(f"导演: {response.director}")
print(f"类型: {', '.join(response.genre)}")
print(f"评分: {response.rating}")

# 可以直接转换为 JSON
print(response.model_dump_json(indent=2))
```

#### 3. 多模态处理示例

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage
import base64

# 读取图像并转换为 base64
def encode_image(image_path: str) -> str:
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

# 初始化支持多模态的模型
model = init_chat_model("gpt-4-vision-preview")

# 创建包含图像的消息
image_data = encode_image("path/to/image.jpg")
message = HumanMessage(
    content=[
        {"type": "text", "text": "这张图片里有什么？"},
        {
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
        }
    ]
)

# 调用模型
response = model.invoke([message])
print(response.content)
```

#### 4. 批量处理示例

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage

model = init_chat_model("gpt-3.5-turbo")

# 准备多个翻译任务
translation_tasks = [
    [HumanMessage(content="将以下文本翻译成英文：你好，世界")],
    [HumanMessage(content="将以下文本翻译成英文：谢谢你的帮助")],
    [HumanMessage(content="将以下文本翻译成英文：今天天气很好")],
    [HumanMessage(content="将以下文本翻译成英文：我喜欢学习编程")]
]

# 批量处理（并行执行）
responses = model.batch(translation_tasks)

# 输出结果
for i, response in enumerate(responses, 1):
    print(f"任务 {i}: {response.content}")
```

#### 5. 流式输出示例

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage

model = init_chat_model("gpt-4", streaming=True)

print("助手: ", end="", flush=True)

for chunk in model.stream([
    HumanMessage(content="写一首关于春天的诗")
]):
    print(chunk.content, end="", flush=True)

print()  # 换行
```

### 支持的提供商

LangChain 支持以下主流 AI 提供商：

| 提供商 | 模型示例 | 特点 |
|--------|----------|------|
| **OpenAI** | gpt-4, gpt-3.5-turbo | 强大的通用能力，支持工具调用 |
| **Anthropic** | claude-sonnet-4-5, claude-opus-4-5 | 长上下文窗口，优秀的推理能力 |
| **Google** | gemini-pro, gemini-ultra | 多模态处理，集成 Google 生态 |
| **Azure OpenAI** | gpt-4, gpt-35-turbo | 企业级支持，数据隐私保证 |
| **AWS Bedrock** | claude, titan | AWS 云集成，多种模型选择 |
| **HuggingFace** | 开源模型 | 自托管，完全控制 |

### 最佳实践

1. **选择合适的模型**
   - 简单任务使用较小、更快的模型（如 gpt-3.5-turbo）
   - 复杂推理使用更强大的模型（如 gpt-4, claude-opus）
   - 多模态任务使用支持视觉的模型

2. **优化性能**
   - 使用批量处理提高吞吐量
   - 使用流式输出改善用户体验
   - 设置合理的超时和重试参数

3. **控制成本**
   - 使用 `max_tokens` 限制输出长度
   - 选择性价比高的模型
   - 对于简单查询使用缓存

4. **提高质量**
   - 调整 `temperature` 控制输出一致性
   - 使用结构化输出确保格式正确
   - 结合工具调用增强能力

---

## 4. Messages (消息)

### 核心概念

Messages（消息）是 LangChain 中的基本上下文单元，用于在用户、模型和系统之间传递信息。每条消息是对话流的构建块。

### 消息的三个核心要素

1. **Role（角色）**：消息类型标识（system、user、ai、tool）
2. **Content（内容）**：实际消息内容（文本、图像、音频等）
3. **Metadata（元数据）**：可选字段（响应信息、消息 ID、token 使用量）

### 四种主要消息类型

#### 1. SystemMessage（系统消息）

设置语气、定义模型角色并建立响应准则的初始指令集。

```python
from langchain_core.messages import SystemMessage

system_msg = SystemMessage(
    content="""你是一个专业的 Python 编程助手。

你的职责：
- 提供清晰、准确的 Python 代码示例
- 解释代码的工作原理
- 遵循 PEP 8 编码规范
- 推荐最佳实践

你的风格：
- 专业但友好
- 耐心解释复杂概念
- 提供实用的代码示例"""
)
```

**使用场景：**
- 定义助手的角色和专业领域
- 设置响应格式和风格
- 提供背景知识和上下文

#### 2. HumanMessage（用户消息）

代表用户输入和交互，支持多模态内容。

```python
from langchain_core.messages import HumanMessage

# 文本消息
text_msg = HumanMessage(content="什么是列表推导式？")

# 带元数据的消息
msg_with_metadata = HumanMessage(
    content="帮我调试这段代码",
    additional_kwargs={
        "user_id": "user_123",
        "timestamp": "2025-12-30T10:30:00Z"
    }
)

# 多模态消息（文本 + 图像）
multimodal_msg = HumanMessage(
    content=[
        {"type": "text", "text": "这段代码有什么问题？"},
        {
            "type": "image_url",
            "image_url": {"url": "data:image/png;base64,iVBORw0..."}
        }
    ]
)
```

**支持的内容类型：**
- 文本
- 图像（URL 或 base64）
- 音频
- 文件
- 混合内容

#### 3. AIMessage（AI 消息）

模型的输出对象，包含响应内容、工具调用和提供商元数据。

```python
from langchain_core.messages import AIMessage

# 简单文本响应
ai_msg = AIMessage(content="列表推导式是一种简洁的创建列表的方式...")

# 带工具调用的响应
ai_msg_with_tools = AIMessage(
    content="让我查询一下数据库",
    tool_calls=[
        {
            "id": "call_123",
            "name": "search_database",
            "args": {"query": "Python tutorials", "limit": 5}
        }
    ]
)

# 访问元数据
print(ai_msg.response_metadata)
# 输出: {'token_usage': {'input_tokens': 10, 'output_tokens': 25}}
```

**AIMessage 的特性：**
- 包含模型生成的文本
- 可以包含工具调用信息
- 记录 token 使用统计
- 支持流式处理（AIMessageChunk）

#### 4. ToolMessage（工具消息）

用于传递工具执行结果给模型。

```python
from langchain_core.messages import ToolMessage

tool_msg = ToolMessage(
    content='{"results": ["Python Tutorial 1", "Python Tutorial 2"]}',
    tool_call_id="call_123",  # 匹配对应的 AIMessage 工具调用 ID
    artifact={"raw_data": [...]}  # 补充数据（不发送给模型）
)
```

**关键属性：**
- `content`：工具输出（通常是字符串或 JSON）
- `tool_call_id`：关联到触发工具的 AIMessage
- `artifact`：额外数据，供程序使用但不发给模型

### 消息内容格式

LangChain 支持三种方式初始化消息内容：

#### 1. 字符串（简单文本）

```python
from langchain_core.messages import HumanMessage

msg = HumanMessage(content="Hello, AI!")
```

#### 2. 提供商原生格式

```python
# OpenAI 格式
msg = HumanMessage(
    content=[
        {"type": "text", "text": "描述这张图片"},
        {"type": "image_url", "image_url": {"url": "https://..."}}
    ]
)
```

#### 3. LangChain 标准内容块

```python
from langchain_core.messages import HumanMessage

msg = HumanMessage(
    content=[
        {"type": "text", "text": "分析这个数据"},
        {"type": "image", "source": "base64", "data": "iVBORw0..."}
    ]
)
```

### 使用方法

#### 1. 基础调用

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage

model = init_chat_model("gpt-4")

messages = [
    SystemMessage(content="你是一个有用的助手"),
    HumanMessage(content="什么是机器学习？")
]

response = model.invoke(messages)
print(response.content)
```

#### 2. 多轮对话

```python
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

messages = [
    SystemMessage(content="你是一个 Python 专家"),
    HumanMessage(content="如何读取文件？"),
    AIMessage(content="使用 `with open('file.txt', 'r') as f:` 语句..."),
    HumanMessage(content="如何写入文件？"),
]

response = model.invoke(messages)
print(response.content)
```

#### 3. 工具调用流程

```python
from langchain.chat_models import init_chat_model
from langchain.tools import tool
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

# 定义工具
@tool
def get_weather(location: str) -> str:
    """获取天气信息"""
    return f"{location} 的天气晴朗"

model = init_chat_model("gpt-4")
model_with_tools = model.bind_tools([get_weather])

# 1. 用户提问
messages = [HumanMessage(content="北京天气怎么样？")]

# 2. 模型决定调用工具
response = model_with_tools.invoke(messages)
messages.append(response)

# 3. 执行工具并添加结果
if response.tool_calls:
    tool_call = response.tool_calls[0]
    tool_result = get_weather.invoke(tool_call["args"])

    messages.append(ToolMessage(
        content=tool_result,
        tool_call_id=tool_call["id"]
    ))

# 4. 模型基于工具结果生成最终回答
final_response = model.invoke(messages)
print(final_response.content)
```

### 代码示例

#### 完整的对话系统

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from typing import List

class ConversationManager:
    """对话管理器"""

    def __init__(self, system_prompt: str, model_name: str = "gpt-4"):
        self.model = init_chat_model(model_name)
        self.messages: List = [SystemMessage(content=system_prompt)]

    def add_user_message(self, content: str):
        """添加用户消息"""
        self.messages.append(HumanMessage(content=content))

    def get_response(self) -> str:
        """获取 AI 响应"""
        response = self.model.invoke(self.messages)
        self.messages.append(response)
        return response.content

    def get_conversation_history(self) -> List[dict]:
        """获取对话历史"""
        history = []
        for msg in self.messages:
            history.append({
                "role": msg.type,
                "content": msg.content
            })
        return history

    def clear_history(self, keep_system: bool = True):
        """清空对话历史"""
        if keep_system:
            self.messages = [self.messages[0]]
        else:
            self.messages = []

# 使用示例
conversation = ConversationManager(
    system_prompt="你是一个专业的编程助手，擅长 Python 和机器学习。"
)

# 第一轮对话
conversation.add_user_message("什么是神经网络？")
print("助手:", conversation.get_response())

# 第二轮对话
conversation.add_user_message("它和深度学习有什么关系？")
print("助手:", conversation.get_response())

# 查看完整对话历史
print("\n完整对话历史:")
for entry in conversation.get_conversation_history():
    print(f"{entry['role']}: {entry['content']}")
```

#### 多模态消息处理

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage
import base64

def encode_image(image_path: str) -> str:
    """将图像编码为 base64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

# 初始化支持视觉的模型
model = init_chat_model("gpt-4-vision-preview")

# 创建多模态消息
image_base64 = encode_image("diagram.png")
message = HumanMessage(
    content=[
        {"type": "text", "text": "请解释这个架构图"},
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{image_base64}",
                "detail": "high"  # 或 "low" 以减少 token 使用
            }
        }
    ]
)

response = model.invoke([message])
print(response.content)
```

### 最佳实践

1. **清晰的系统提示**
   - 明确定义角色和职责
   - 提供具体的行为准则
   - 包含格式要求

2. **结构化对话历史**
   - 保持消息序列的逻辑性
   - 适时清理历史避免上下文过长
   - 使用消息元数据追踪对话

3. **多模态处理**
   - 优化图像大小以减少 token 消耗
   - 使用 `detail` 参数控制图像处理精度
   - 提供清晰的文本描述配合图像

4. **工具调用**
   - 确保 `tool_call_id` 正确匹配
   - 提供清晰的工具执行结果
   - 处理工具执行错误

---

## 5. Tools (工具)

### 核心概念

工具（Tools）是具有明确定义的输入和输出的可调用函数。聊天模型决定何时调用工具以及传递什么参数。工具使代理能够与外部系统交互、执行计算和获取实时数据。

### 创建工具的方法

#### 1. 基础工具定义（@tool 装饰器）

使用 `@tool` 装饰器是最简单的方式：

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """在客户数据库中搜索信息

    Args:
        query: 搜索查询字符串
        limit: 返回结果的最大数量（默认 10）

    Returns:
        搜索结果的 JSON 字符串
    """
    # 实际的数据库查询逻辑
    results = {"query": query, "count": 3, "results": [...]}
    return str(results)
```

**关键要点：**
- **Docstring 很重要**：自动成为工具描述，帮助模型理解使用时机
- **类型提示必需**：定义工具的输入模式
- **返回值应为字符串**：便于模型理解

#### 2. 自定义工具属性

```python
from langchain.tools import tool

# 自定义工具名称
@tool("custom_search")
def search(query: str) -> str:
    """搜索信息"""
    return f"结果: {query}"

# 自定义工具描述
@tool(description="这是一个增强的搜索工具，可以搜索多个数据源")
def enhanced_search(query: str, sources: list[str]) -> str:
    """搜索多个数据源"""
    return f"从 {sources} 搜索 {query}"
```

#### 3. 使用 Pydantic 模型定义复杂输入

```python
from langchain.tools import tool
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    """搜索工具的输入参数"""
    query: str = Field(..., description="搜索查询字符串")
    limit: int = Field(10, description="最大结果数", ge=1, le=100)
    filters: dict = Field(default_factory=dict, description="过滤条件")
    sort_by: str = Field("relevance", description="排序方式")

@tool(args_schema=SearchInput)
def advanced_search(query: str, limit: int = 10, filters: dict = None, sort_by: str = "relevance") -> str:
    """执行高级搜索

    支持过滤、排序和分页功能
    """
    filters = filters or {}
    return f"搜索 '{query}'，限制 {limit} 条，过滤器: {filters}"
```

#### 4. 使用 JSON Schema 定义

```python
from langchain.tools import tool

search_schema = {
    "type": "object",
    "properties": {
        "query": {"type": "string", "description": "搜索查询"},
        "limit": {"type": "integer", "minimum": 1, "maximum": 100}
    },
    "required": ["query"]
}

@tool(args_schema=search_schema)
def json_schema_search(query: str, limit: int = 10) -> str:
    """使用 JSON Schema 定义的搜索工具"""
    return f"搜索: {query}"
```

### 运行时访问（ToolRuntime）

工具可以通过 `ToolRuntime` 参数访问运行时上下文：

```python
from langchain.tools import tool, ToolRuntime

@tool
def personalized_greeting(name: str, runtime: ToolRuntime) -> str:
    """生成个性化问候语"""

    # 访问状态（可变数据）
    message_count = len(runtime.state.get("messages", []))

    # 访问上下文（不可变配置）
    user_id = runtime.context.get("user_id", "unknown")

    # 访问存储（长期记忆）
    user_prefs = runtime.store.get(user_id, {})

    # 使用流式写入器
    runtime.stream_writer.write(f"正在为 {name} 生成问候语...")

    return f"你好 {name}！这是你的第 {message_count} 条消息。"
```

**ToolRuntime 提供的访问：**
- **State（状态）**：可变数据（消息、计数器、自定义字段）
- **Context（上下文）**：不可变配置（用户 ID、会话详情）
- **Store（存储）**：跨对话的持久化长期记忆
- **Stream Writer（流式写入器）**：实时流式输出工具执行进度

### 代码示例

#### 1. 基础工具集

```python
from langchain.tools import tool
import requests
from datetime import datetime

@tool
def get_current_time(timezone: str = "UTC") -> str:
    """获取当前时间

    Args:
        timezone: 时区（如：UTC, Asia/Shanghai）

    Returns:
        当前时间字符串
    """
    now = datetime.now()
    return f"当前时间（{timezone}）: {now.strftime('%Y-%m-%d %H:%M:%S')}"

@tool
def fetch_url(url: str) -> str:
    """获取 URL 的内容

    Args:
        url: 要获取的网页 URL

    Returns:
        网页内容的前 500 个字符
    """
    try:
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        return response.text[:500]
    except Exception as e:
        return f"错误: {str(e)}"

@tool
def calculate(expression: str) -> str:
    """计算数学表达式

    Args:
        expression: 数学表达式（如：2 + 2, 10 * 5）

    Returns:
        计算结果
    """
    try:
        # 注意：在生产环境中应使用更安全的方式
        result = eval(expression, {"__builtins__": {}})
        return f"{expression} = {result}"
    except Exception as e:
        return f"计算错误: {str(e)}"
```

#### 2. 数据库查询工具

```python
from langchain.tools import tool
from pydantic import BaseModel, Field
import json

class DatabaseQuery(BaseModel):
    """数据库查询参数"""
    table: str = Field(..., description="要查询的表名")
    filters: dict = Field(default_factory=dict, description="查询过滤条件")
    limit: int = Field(10, description="返回记录数", ge=1, le=100)

@tool(args_schema=DatabaseQuery)
def query_database(table: str, filters: dict = None, limit: int = 10) -> str:
    """查询数据库

    支持过滤和分页
    """
    filters = filters or {}

    # 模拟数据库查询
    mock_data = {
        "users": [
            {"id": 1, "name": "张三", "age": 25},
            {"id": 2, "name": "李四", "age": 30},
        ],
        "products": [
            {"id": 1, "name": "笔记本电脑", "price": 5999},
            {"id": 2, "name": "手机", "price": 3999},
        ]
    }

    results = mock_data.get(table, [])[:limit]
    return json.dumps({"table": table, "results": results}, ensure_ascii=False)

@tool
def update_database(table: str, record_id: int, updates: dict) -> str:
    """更新数据库记录

    Args:
        table: 表名
        record_id: 记录 ID
        updates: 要更新的字段和值

    Returns:
        更新结果
    """
    return json.dumps({
        "status": "success",
        "table": table,
        "id": record_id,
        "updated_fields": list(updates.keys())
    }, ensure_ascii=False)
```

#### 3. 带运行时上下文的工具

```python
from langchain.tools import tool, ToolRuntime
from typing import Optional

@tool
def track_user_action(action: str, runtime: ToolRuntime) -> str:
    """跟踪用户操作

    记录用户行为并更新状态
    """
    # 从上下文获取用户信息
    user_id = runtime.context.get("user_id", "anonymous")

    # 从状态获取当前计数
    current_state = runtime.state
    action_count = current_state.get("action_count", 0)

    # 更新计数
    action_count += 1

    # 流式输出进度
    runtime.stream_writer.write(f"记录用户 {user_id} 的操作...")

    # 保存到长期存储
    user_history = runtime.store.get(user_id, [])
    user_history.append({
        "action": action,
        "timestamp": datetime.now().isoformat(),
        "count": action_count
    })
    runtime.store.set(user_id, user_history)

    return f"已记录操作 '{action}'，这是你的第 {action_count} 次操作"

@tool
def get_user_preferences(runtime: ToolRuntime) -> str:
    """获取用户偏好设置"""
    user_id = runtime.context.get("user_id", "anonymous")
    prefs = runtime.store.get(f"{user_id}_prefs", {
        "language": "zh-CN",
        "theme": "light"
    })
    return json.dumps(prefs, ensure_ascii=False)
```

#### 4. 文件操作工具

```python
from langchain.tools import tool
import os
from pathlib import Path

@tool
def read_file(file_path: str, encoding: str = "utf-8") -> str:
    """读取文件内容

    Args:
        file_path: 文件路径
        encoding: 文件编码（默认 utf-8）

    Returns:
        文件内容
    """
    try:
        with open(file_path, "r", encoding=encoding) as f:
            content = f.read()
        return f"文件 {file_path} 的内容:\n{content}"
    except Exception as e:
        return f"读取文件失败: {str(e)}"

@tool
def write_file(file_path: str, content: str, encoding: str = "utf-8") -> str:
    """写入文件

    Args:
        file_path: 文件路径
        content: 要写入的内容
        encoding: 文件编码（默认 utf-8）

    Returns:
        写入结果
    """
    try:
        # 确保目录存在
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)

        with open(file_path, "w", encoding=encoding) as f:
            f.write(content)

        return f"成功写入 {len(content)} 字符到 {file_path}"
    except Exception as e:
        return f"写入文件失败: {str(e)}"

@tool
def list_directory(directory: str) -> str:
    """列出目录内容

    Args:
        directory: 目录路径

    Returns:
        目录中的文件和文件夹列表
    """
    try:
        items = os.listdir(directory)
        files = [item for item in items if os.path.isfile(os.path.join(directory, item))]
        dirs = [item for item in items if os.path.isdir(os.path.join(directory, item))]

        result = {
            "directory": directory,
            "files": files,
            "directories": dirs
        }
        return json.dumps(result, ensure_ascii=False)
    except Exception as e:
        return f"列出目录失败: {str(e)}"
```

#### 5. 使用工具的完整示例

```python
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.checkpoint.memory import InMemorySaver
import json

# 定义工具集
@tool
def search_products(query: str, category: str = "all") -> str:
    """搜索产品"""
    products = [
        {"id": 1, "name": "笔记本电脑", "price": 5999, "category": "电子"},
        {"id": 2, "name": "Python 编程书", "price": 89, "category": "图书"},
        {"id": 3, "name": "机械键盘", "price": 599, "category": "电子"}
    ]

    if category != "all":
        products = [p for p in products if p["category"] == category]

    if query:
        products = [p for p in products if query.lower() in p["name"].lower()]

    return json.dumps(products, ensure_ascii=False)

@tool
def get_product_details(product_id: int) -> str:
    """获取产品详情"""
    products = {
        1: {"id": 1, "name": "笔记本电脑", "price": 5999, "stock": 15, "description": "高性能笔记本"},
        2: {"id": 2, "name": "Python 编程书", "price": 89, "stock": 50, "description": "零基础学 Python"},
        3: {"id": 3, "name": "机械键盘", "price": 599, "stock": 30, "description": "Cherry 轴机械键盘"}
    }

    product = products.get(product_id)
    if product:
        return json.dumps(product, ensure_ascii=False)
    return "产品未找到"

@tool
def check_inventory(product_id: int) -> str:
    """检查库存"""
    inventory = {1: 15, 2: 50, 3: 30}
    stock = inventory.get(product_id, 0)
    return json.dumps({
        "product_id": product_id,
        "stock": stock,
        "available": stock > 0
    }, ensure_ascii=False)

# 创建代理
agent = create_agent(
    model="gpt-4",
    tools=[search_products, get_product_details, check_inventory],
    system_prompt="""你是一个电商助手，可以帮助用户：
    1. 搜索产品
    2. 查看产品详情
    3. 检查库存

    始终提供友好、准确的信息。""",
    checkpointer=InMemorySaver()
)

# 使用代理
config = {"thread_id": "shopping_session_1"}

queries = [
    "帮我找找电子产品",
    "笔记本电脑的详细信息",
    "这个产品有货吗？"
]

for query in queries:
    print(f"\n用户: {query}")
    result = agent.invoke({
        "messages": [{"role": "user", "content": query}]
    }, config=config)
    print(f"助手: {result['messages'][-1]['content']}")
```

### 工具的高级特性

#### 1. 并行工具调用

模型可以同时调用多个工具：

```python
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """获取天气"""
    return f"{city}: 晴天 22°C"

@tool
def get_time(timezone: str) -> str:
    """获取时间"""
    return f"{timezone}: 14:30"

# 模型可能会并行调用这两个工具
# 用户: "北京的天气和时间"
# 模型会同时调用 get_weather("北京") 和 get_time("Asia/Shanghai")
```

#### 2. 错误处理

```python
from langchain.tools import tool

@tool
def safe_divide(a: float, b: float) -> str:
    """安全除法"""
    try:
        if b == 0:
            return "错误: 除数不能为零"
        result = a / b
        return f"{a} ÷ {b} = {result}"
    except Exception as e:
        return f"计算错误: {str(e)}"
```

#### 3. 工具链

一个工具的输出可以作为另一个工具的输入：

```python
@tool
def search_user(name: str) -> str:
    """搜索用户并返回用户 ID"""
    return json.dumps({"user_id": 123, "name": name})

@tool
def get_user_orders(user_id: int) -> str:
    """获取用户订单"""
    return json.dumps([{"order_id": "ORD001", "total": 299}])

# 模型可以先调用 search_user，然后使用返回的 user_id 调用 get_user_orders
```

### 保留参数名

- `config`：保留用于配置参数
- `runtime`：保留用于 ToolRuntime

这些参数名不能用作工具的输入参数。

### 最佳实践

1. **清晰的文档**
   - 编写详细的 docstring
   - 明确说明参数类型和用途
   - 提供返回值示例

2. **类型安全**
   - 始终使用类型提示
   - 使用 Pydantic 模型验证复杂输入
   - 处理边界情况

3. **错误处理**
   - 捕获并返回有意义的错误信息
   - 避免工具崩溃
   - 提供降级方案

4. **性能优化**
   - 添加超时限制
   - 缓存常用结果
   - 异步执行耗时操作

5. **安全考虑**
   - 验证输入参数
   - 限制文件系统访问
   - 避免执行任意代码（慎用 `eval`）

---

## 6. Short-term Memory (短期记忆)

### 核心概念

短期记忆使应用能够在单个线程或对话中记住之前的交互。系统通过线程（thread）组织多个交互，类似于电子邮件将消息分组在单个对话中的方式。

**短期记忆的作用：**
- 维持对话上下文
- 记住用户偏好和信息
- 支持多轮对话
- 避免重复询问相同问题

### 实现方式

#### 1. 基础设置

通过在创建代理时指定 `checkpointer` 来添加短期记忆：

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.checkpoint.postgres import PostgresSaver

# 开发环境：使用内存存储
agent = create_agent(
    model="gpt-4",
    tools=[search_tool],
    checkpointer=InMemorySaver()
)

# 生产环境：使用数据库持久化
agent = create_agent(
    model="gpt-4",
    tools=[search_tool],
    checkpointer=PostgresSaver(
        connection_string="postgresql://user:pass@localhost/dbname"
    )
)
```

#### 2. 使用线程管理对话

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

agent = create_agent(
    model="gpt-4",
    tools=[search_tool],
    checkpointer=InMemorySaver()
)

# 用户 A 的对话
config_a = {"thread_id": "user_a_session_1"}
agent.invoke({
    "messages": [{"role": "user", "content": "我的名字是张三"}]
}, config=config_a)

agent.invoke({
    "messages": [{"role": "user", "content": "我叫什么名字？"}]
}, config=config_a)
# 输出: "你的名字是张三"

# 用户 B 的对话（独立的线程）
config_b = {"thread_id": "user_b_session_1"}
agent.invoke({
    "messages": [{"role": "user", "content": "我叫什么名字？"}]
}, config=config_b)
# 输出: "我不知道你的名字，请告诉我"
```

### 自定义状态

可以扩展 `AgentState` 来添加自定义字段：

```python
from typing import TypedDict, Annotated
from langchain.agents import create_agent
from langgraph.graph import add_messages

class CustomAgentState(TypedDict):
    """自定义代理状态"""
    messages: Annotated[list, add_messages]  # 消息列表
    user_id: str                              # 用户 ID
    user_preferences: dict                    # 用户偏好
    session_count: int                        # 会话计数
    context: dict                             # 额外上下文

agent = create_agent(
    model="gpt-4",
    tools=[personalized_tool],
    state_schema=CustomAgentState,
    checkpointer=InMemorySaver()
)

# 使用自定义状态
result = agent.invoke({
    "messages": [{"role": "user", "content": "推荐一本书"}],
    "user_id": "user_123",
    "user_preferences": {"genre": "科幻", "language": "中文"},
    "session_count": 1,
    "context": {"source": "mobile_app"}
}, config={"thread_id": "session_1"})
```

### 常见记忆管理策略

#### 1. 修剪消息（Message Trimming）

移除前 N 个或最后 N 个消息，保留最近的交互：

```python
from langchain_core.messages import trim_messages

def trim_old_messages(messages: list, max_messages: int = 10) -> list:
    """保留最近的 N 条消息"""
    return trim_messages(
        messages,
        max_tokens=None,
        strategy="last",
        token_counter=len,
        include_system=True,
        start_on="human"
    )[-max_messages:]

# 在中间件中使用
from langchain.agents import create_agent, before_model

@before_model
def trim_middleware(state):
    """修剪消息的中间件"""
    state["messages"] = trim_old_messages(state["messages"], max_messages=10)
    return state

agent = create_agent(
    model="gpt-4",
    tools=[],
    middleware=[trim_middleware]
)
```

#### 2. 删除消息（Remove Messages）

使用 `RemoveMessage` 永久删除特定或全部消息：

```python
from langchain_core.messages import RemoveMessage
from langchain.tools import tool, ToolRuntime

@tool
def clear_sensitive_data(runtime: ToolRuntime) -> str:
    """清除敏感数据"""
    messages = runtime.state["messages"]

    # 找到包含敏感信息的消息
    messages_to_remove = [
        msg for msg in messages
        if "密码" in msg.content or "信用卡" in msg.content
    ]

    # 创建删除指令
    remove_commands = [RemoveMessage(id=msg.id) for msg in messages_to_remove]

    return f"已删除 {len(remove_commands)} 条敏感消息"

# 清空所有历史
@tool
def clear_conversation_history(runtime: ToolRuntime) -> str:
    """清空对话历史"""
    messages = runtime.state["messages"]

    # 保留系统消息，删除其他所有消息
    remove_commands = [
        RemoveMessage(id=msg.id)
        for msg in messages
        if msg.type != "system"
    ]

    return f"已清空 {len(remove_commands)} 条对话记录"
```

#### 3. 总结消息（Summarization）

通过 `SummarizationMiddleware` 将早期消息压缩为摘要：

```python
from langchain.agents import create_agent, SummarizationMiddleware
from langchain.chat_models import init_chat_model

# 创建总结中间件
summarization = SummarizationMiddleware(
    model=init_chat_model("gpt-3.5-turbo"),
    max_messages=20,  # 超过 20 条消息时触发总结
    summary_prompt="将以下对话总结成简洁的要点："
)

agent = create_agent(
    model="gpt-4",
    tools=[],
    middleware=[summarization],
    checkpointer=InMemorySaver()
)
```

### 访问与修改状态

#### 1. 在工具中读取状态

```python
from langchain.tools import tool, ToolRuntime

@tool
def get_conversation_stats(runtime: ToolRuntime) -> str:
    """获取对话统计信息"""
    messages = runtime.state["messages"]

    stats = {
        "total_messages": len(messages),
        "user_messages": len([m for m in messages if m.type == "human"]),
        "ai_messages": len([m for m in messages if m.type == "ai"]),
        "tool_calls": len([m for m in messages if m.type == "tool"])
    }

    return json.dumps(stats, ensure_ascii=False)
```

#### 2. 在工具中写入状态

```python
from langchain.tools import tool, ToolRuntime
from langchain_core.messages import Command

@tool
def update_user_preference(preference_key: str, preference_value: str, runtime: ToolRuntime) -> str:
    """更新用户偏好"""
    current_prefs = runtime.state.get("user_preferences", {})
    current_prefs[preference_key] = preference_value

    # 返回 Command 对象以更新状态
    return Command(
        update={
            "user_preferences": current_prefs
        },
        content=f"已更新偏好: {preference_key} = {preference_value}"
    )
```

#### 3. 在中间件中处理状态

```python
from langchain.agents import create_agent, before_model, after_model

@before_model
def log_before_model(state):
    """模型调用前记录状态"""
    print(f"消息数量: {len(state['messages'])}")
    return state

@after_model
def log_after_model(state):
    """模型调用后记录状态"""
    last_message = state["messages"][-1]
    print(f"模型响应: {last_message.content[:50]}...")
    return state

agent = create_agent(
    model="gpt-4",
    tools=[],
    middleware=[log_before_model, log_after_model]
)
```

### 代码示例

#### 完整的记忆管理示例

```python
from langchain.agents import create_agent, before_model
from langchain.tools import tool, ToolRuntime
from langgraph.checkpoint.memory import InMemorySaver
from typing import TypedDict, Annotated
from langchain_core.messages import trim_messages, add_messages, RemoveMessage
import json

# 自定义状态
class ConversationState(TypedDict):
    messages: Annotated[list, add_messages]
    user_id: str
    conversation_summary: str
    message_count: int
    user_preferences: dict

# 工具定义
@tool
def save_preference(key: str, value: str, runtime: ToolRuntime) -> str:
    """保存用户偏好"""
    prefs = runtime.state.get("user_preferences", {})
    prefs[key] = value
    runtime.state["user_preferences"] = prefs
    return f"已保存偏好: {key} = {value}"

@tool
def get_preferences(runtime: ToolRuntime) -> str:
    """获取用户偏好"""
    prefs = runtime.state.get("user_preferences", {})
    return json.dumps(prefs, ensure_ascii=False)

@tool
def get_summary(runtime: ToolRuntime) -> str:
    """获取对话摘要"""
    summary = runtime.state.get("conversation_summary", "暂无摘要")
    return summary

# 消息修剪中间件
@before_model
def trim_middleware(state):
    """保留最近 15 条消息"""
    if len(state["messages"]) > 15:
        # 保留系统消息和最近 15 条
        system_msgs = [m for m in state["messages"] if m.type == "system"]
        recent_msgs = state["messages"][-15:]
        state["messages"] = system_msgs + recent_msgs

    # 更新计数
    state["message_count"] = len(state["messages"])

    return state

# 创建代理
agent = create_agent(
    model="gpt-4",
    tools=[save_preference, get_preferences, get_summary],
    state_schema=ConversationState,
    middleware=[trim_middleware],
    checkpointer=InMemorySaver(),
    system_prompt="""你是一个智能助手，可以：
    1. 记住用户偏好
    2. 维持对话上下文
    3. 提供个性化服务

    使用工具来保存和获取用户偏好。"""
)

# 使用示例
def chat(user_input: str, thread_id: str, user_id: str = "user_001"):
    """与代理对话"""
    config = {"thread_id": thread_id}

    result = agent.invoke({
        "messages": [{"role": "user", "content": user_input}],
        "user_id": user_id,
        "conversation_summary": "",
        "message_count": 0,
        "user_preferences": {}
    }, config=config)

    return result["messages"][-1]["content"]

# 对话示例
thread = "session_001"

print(chat("我喜欢科幻小说", thread))
print(chat("记住我的这个偏好", thread))
print(chat("我喜欢什么类型的书？", thread))
print(chat("推荐一本书给我", thread))
```

#### 数据库持久化示例

```python
from langgraph.checkpoint.postgres import PostgresSaver
from langchain.agents import create_agent
import os

# 配置 PostgreSQL 连接
connection_string = os.getenv(
    "POSTGRES_URI",
    "postgresql://user:password@localhost:5432/langchain_db"
)

# 创建持久化存储
checkpointer = PostgresSaver(connection_string)

# 创建代理
agent = create_agent(
    model="gpt-4",
    tools=[search_tool, save_tool],
    checkpointer=checkpointer,
    system_prompt="你是一个有记忆的助手"
)

# 使用代理（对话会持久化到数据库）
config = {"thread_id": "persistent_session_1"}

result1 = agent.invoke({
    "messages": [{"role": "user", "content": "记住：我的生日是 1990-01-01"}]
}, config=config)

# 即使程序重启，记忆也会保留
result2 = agent.invoke({
    "messages": [{"role": "user", "content": "我的生日是什么时候？"}]
}, config=config)
```

### 关键优势

1. **长对话支持**：处理超过模型上下文窗口的长对话
2. **个性化体验**：记住用户偏好和历史交互
3. **会话隔离**：通过线程 ID 隔离不同用户/会话
4. **性能优化**：通过修剪和总结减少 token 消耗
5. **持久化存储**：支持跨会话的数据保留

### 最佳实践

1. **选择合适的存储**
   - 开发/测试：InMemorySaver
   - 生产环境：PostgresSaver 或其他数据库

2. **管理上下文长度**
   - 实施消息修剪策略
   - 使用总结压缩旧消息
   - 监控 token 使用量

3. **隐私和安全**
   - 定期清理敏感信息
   - 实施数据保留策略
   - 加密存储的对话数据

4. **性能优化**
   - 缓存常用查询
   - 异步写入数据库
   - 批量处理更新

---

## 7. Streaming (流式输出)

### 核心概念

LangChain 的流式处理系统通过实时显示输出来改善用户体验。流式处理对于增强 LLM 应用的响应能力至关重要，它允许在完整响应生成前就展示渐进式结果。

**流式输出的优势：**
- 改善用户体验（即时反馈）
- 减少感知延迟
- 实时显示长文本生成
- 展示中间处理步骤

### 三种流式模式

| 模式 | 功能 | 使用场景 |
|------|------|----------|
| **updates** | 在每个代理步骤后流式传输状态更新 | 显示代理执行进度 |
| **messages** | 从图形节点流式传输 LLM 生成的令牌元组 | 逐字显示 AI 响应 |
| **custom** | 使用流写入器从图形节点流式传输自定义数据 | 工具执行进度、自定义事件 |

### 实现方式

#### 1. 代理进行流式处理（updates）

在每个执行步骤后获得事件：

```python
from langchain.agents import create_agent
from langchain.tools import tool

@tool
def search_database(query: str) -> str:
    """搜索数据库"""
    return f"找到关于 '{query}' 的 5 条结果"

agent = create_agent(
    model="gpt-4",
    tools=[search_database]
)

# 流式输出代理执行步骤
for event in agent.stream({
    "messages": [{"role": "user", "content": "搜索 Python 教程"}]
}, stream_mode="updates"):
    print("执行步骤:", event)
    print("---")
```

**典型的事件流程：**
```
1. LLM 节点 → 返回工具调用请求
2. 工具节点 → 返回工具执行结果
3. LLM 节点 → 返回最终响应
```

#### 2. LLM 令牌流式处理（messages）

逐个流式传输生成的令牌：

```python
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4",
    tools=[]
)

# 流式输出每个令牌
print("助手: ", end="", flush=True)

for chunk in agent.stream({
    "messages": [{"role": "user", "content": "解释什么是机器学习"}]
}, stream_mode="messages"):
    # chunk 是 (langgraph_node, message_chunk) 元组
    node, message = chunk
    if hasattr(message, 'content'):
        print(message.content, end="", flush=True)

print()  # 换行
```

#### 3. 自定义流式更新（custom）

利用 `get_stream_writer()` 实现任意数据流式传输：

```python
from langchain.tools import tool
from langgraph.types import StreamWriter

@tool
def process_large_file(file_path: str, stream: StreamWriter) -> str:
    """处理大文件并流式输出进度

    注意：使用 stream 参数后，此工具只能在 LangGraph 上下文中调用
    """
    total_lines = 1000

    for i in range(0, total_lines, 100):
        # 处理逻辑...
        progress = (i + 100) / total_lines * 100

        # 流式输出进度
        stream({"progress": progress, "status": f"已处理 {i + 100} 行"})

    return f"完成！共处理 {total_lines} 行"

# 使用自定义流式输出
for event in agent.stream({
    "messages": [{"role": "user", "content": "处理这个文件"}]
}, stream_mode="custom"):
    print(f"进度: {event}")
```

**重要警告：**
- 在工具内添加 `StreamWriter` 参数后，该工具无法在 LangGraph 执行上下文外调用
- 只在需要流式反馈的工具中使用此功能

### 高级特性

#### 1. 多模式流式处理

同时使用多个流式模式：

```python
from langchain.agents import create_agent

agent = create_agent(
    model="gpt-4",
    tools=[search_tool]
)

# 同时获取步骤更新和自定义事件
for mode, chunk in agent.stream({
    "messages": [{"role": "user", "content": "搜索并分析数据"}]
}, stream_mode=["updates", "custom"]):

    if mode == "updates":
        print(f"[步骤] {chunk}")
    elif mode == "custom":
        print(f"[自定义] {chunk}")
```

输出格式：`(mode, chunk)` 元组

#### 2. 禁用流式处理

在某些情况下可能需要禁用流式输出：

```python
from langchain.chat_models import init_chat_model

# 禁用流式处理的模型
model = init_chat_model(
    "gpt-4",
    streaming=False  # 禁用流式输出
)

# 使用场景：
# - 控制多代理系统中的输出
# - 兼容不支持流式的模型
# - 批量处理时减少开销
```

#### 3. 子代理流式处理

在多代理系统中区分不同 LLM 的输出：

```python
from langchain.chat_models import init_chat_model
from langchain.agents import create_agent

# 为不同模型添加标签
model_a = init_chat_model("gpt-4", tags=["agent_a"])
model_b = init_chat_model("claude-3", tags=["agent_b"])

agent_a = create_agent(model=model_a, tools=[])
agent_b = create_agent(model=model_b, tools=[])

# 流式输出时区分来源
for chunk in agent_a.stream({
    "messages": [{"role": "user", "content": "你好"}]
}, stream_mode="messages", subgraphs=True):
    node, message = chunk
    if hasattr(message, 'tags') and 'agent_a' in message.tags:
        print(f"[Agent A]: {message.content}", end="")
```

### 代码示例

#### 1. 基础流式输出

```python
from langchain.agents import create_agent
from langchain.chat_models import init_chat_model

# 创建支持流式输出的代理
model = init_chat_model("gpt-4", streaming=True)
agent = create_agent(model=model, tools=[])

def stream_chat(user_input: str):
    """流式输出聊天响应"""
    print("助手: ", end="", flush=True)

    for chunk in agent.stream({
        "messages": [{"role": "user", "content": user_input}]
    }, stream_mode="messages"):
        _, message = chunk
        if hasattr(message, 'content') and message.content:
            print(message.content, end="", flush=True)

    print()  # 换行

# 使用
stream_chat("写一首关于春天的诗")
```

#### 2. 显示代理执行步骤

```python
from langchain.agents import create_agent
from langchain.tools import tool
import time

@tool
def step1_analyze(data: str) -> str:
    """分析数据"""
    time.sleep(1)  # 模拟耗时操作
    return f"已分析: {data}"

@tool
def step2_process(analysis: str) -> str:
    """处理分析结果"""
    time.sleep(1)
    return f"已处理: {analysis}"

agent = create_agent(
    model="gpt-4",
    tools=[step1_analyze, step2_process],
    system_prompt="按步骤执行任务"
)

# 流式显示执行步骤
print("开始执行任务...\n")

for event in agent.stream({
    "messages": [{"role": "user", "content": "分析并处理这些数据: [1,2,3]"}]
}, stream_mode="updates"):

    # 解析事件
    if "agent" in event:
        print("🤖 代理思考中...")
    elif "tools" in event:
        print("🔧 执行工具...")
        print(f"   结果: {event['tools']}")

    print()
```

#### 3. 自定义进度流式输出

```python
from langchain.tools import tool
from langgraph.types import StreamWriter
from langchain.agents import create_agent
import time

@tool
def analyze_data(dataset: str, stream: StreamWriter) -> str:
    """分析数据集并报告进度"""
    steps = ["加载数据", "清洗数据", "特征工程", "模型训练", "生成报告"]

    for i, step in enumerate(steps, 1):
        # 模拟处理
        time.sleep(0.5)

        # 流式输出进度
        progress = {
            "step": i,
            "total": len(steps),
            "current": step,
            "percentage": i / len(steps) * 100
        }
        stream(progress)

    return "分析完成！"

agent = create_agent(
    model="gpt-4",
    tools=[analyze_data]
)

# 使用自定义流式输出
print("分析进度:")
print("-" * 50)

for event in agent.stream({
    "messages": [{"role": "user", "content": "分析销售数据集"}]
}, stream_mode="custom"):

    if isinstance(event, dict) and "percentage" in event:
        print(f"[{event['step']}/{event['total']}] {event['current']} - {event['percentage']:.1f}%")

print("-" * 50)
print("✓ 完成")
```

#### 4. 实时聊天应用

```python
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.checkpoint.memory import InMemorySaver
import sys

@tool
def search_knowledge(query: str) -> str:
    """搜索知识库"""
    return f"找到关于 '{query}' 的信息..."

agent = create_agent(
    model="gpt-4",
    tools=[search_knowledge],
    checkpointer=InMemorySaver()
)

def chat_stream(thread_id: str = "default"):
    """交互式流式聊天"""
    config = {"thread_id": thread_id}

    print("欢迎！输入 'exit' 退出。\n")

    while True:
        # 获取用户输入
        user_input = input("你: ").strip()

        if user_input.lower() == 'exit':
            print("再见！")
            break

        if not user_input:
            continue

        # 流式输出响应
        print("助手: ", end="", flush=True)

        full_response = ""
        for chunk in agent.stream({
            "messages": [{"role": "user", "content": user_input}]
        }, config=config, stream_mode="messages"):

            _, message = chunk
            if hasattr(message, 'content') and message.content:
                print(message.content, end="", flush=True)
                full_response += message.content

        print("\n")  # 换行

# 运行聊天
chat_stream("session_001")
```

#### 5. 多模式流式监控

```python
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.types import StreamWriter
import json

@tool
def complex_task(task: str, stream: StreamWriter) -> str:
    """执行复杂任务"""
    steps = ["初始化", "执行", "验证", "完成"]

    for step in steps:
        stream({"task": task, "step": step})

    return f"任务 '{task}' 完成"

agent = create_agent(
    model="gpt-4",
    tools=[complex_task]
)

# 同时监控多种事件
for mode, data in agent.stream({
    "messages": [{"role": "user", "content": "执行数据分析任务"}]
}, stream_mode=["updates", "custom", "messages"]):

    if mode == "updates":
        print(f"📊 [步骤更新] {list(data.keys())}")

    elif mode == "custom":
        print(f"🔔 [自定义事件] {json.dumps(data, ensure_ascii=False)}")

    elif mode == "messages":
        node, message = data
        if hasattr(message, 'content') and message.content:
            print(f"💬 [消息] {message.content[:50]}...")
```

### 常见应用场景

#### 1. 人类在环流程（Human-in-the-Loop）

```python
from langchain.agents import create_agent
from langchain.tools import tool

@tool
def request_approval(action: str) -> str:
    """请求人类批准"""
    print(f"\n⚠️  需要批准: {action}")
    response = input("批准? (y/n): ")
    return "已批准" if response.lower() == 'y' else "已拒绝"

agent = create_agent(
    model="gpt-4",
    tools=[request_approval]
)

# 流式显示并等待人类输入
for event in agent.stream({
    "messages": [{"role": "user", "content": "删除旧数据"}]
}, stream_mode="updates"):
    print(event)
```

#### 2. 工具调用处理

```python
# 既流式传输部分 JSON 也流式传输完整解析的工具调用
for chunk in agent.stream({
    "messages": [{"role": "user", "content": "搜索并总结信息"}]
}, stream_mode="messages"):

    node, message = chunk

    # 显示工具调用
    if hasattr(message, 'tool_calls') and message.tool_calls:
        for tool_call in message.tool_calls:
            print(f"🔧 调用工具: {tool_call['name']}")
            print(f"   参数: {tool_call['args']}")

    # 显示文本内容
    if hasattr(message, 'content') and message.content:
        print(message.content, end="", flush=True)
```

#### 3. 安全防护中间件

```python
from langchain.agents import create_agent, after_model
from langgraph.types import StreamWriter

@after_model
def safety_check(state, stream: StreamWriter):
    """检查输出安全性"""
    last_message = state["messages"][-1]
    content = last_message.content

    # 检查敏感词
    sensitive_words = ["密码", "信用卡", "私钥"]
    for word in sensitive_words:
        if word in content:
            stream({"warning": f"检测到敏感词: {word}"})
            # 可以选择修改或阻止输出

    return state

agent = create_agent(
    model="gpt-4",
    tools=[],
    middleware=[safety_check]
)
```

### 最佳实践

1. **选择合适的流式模式**
   - 简单聊天：使用 `messages` 模式
   - 调试代理：使用 `updates` 模式
   - 自定义反馈：使用 `custom` 模式

2. **优化用户体验**
   - 提供实时反馈
   - 显示进度指示器
   - 处理流式中断

3. **性能考虑**
   - 避免过于频繁的流式更新
   - 批量处理小型更新
   - 使用异步流式处理

4. **错误处理**
   - 捕获流式过程中的异常
   - 提供降级方案
   - 记录流式事件用于调试

---

## 8. Structured Output (结构化输出)

### 核心概念

结构化输出允许代理以特定、可预测的格式返回数据，使应用程序能直接使用 JSON 对象、Pydantic 模型或数据类，而无需解析自然语言响应。

**结构化输出的优势：**
- 消除解析错误
- 确保数据格式一致
- 简化下游处理
- 支持类型验证
- 便于集成到应用程序

### 两种实现策略

#### 1. 提供商策略（ProviderStrategy）

适用于原生支持结构化输出的模型（OpenAI、Anthropic、Grok 等）。

```python
from langchain.agents import create_agent, ProviderStrategy
from pydantic import BaseModel, Field

class WeatherReport(BaseModel):
    """天气报告"""
    location: str = Field(..., description="城市名称")
    temperature: float = Field(..., description="温度（摄氏度）")
    condition: str = Field(..., description="天气状况")
    humidity: int = Field(..., description="湿度（百分比）")
    forecast: list[str] = Field(..., description="未来 3 天预报")

agent = create_agent(
    model="gpt-4",
    tools=[weather_tool],
    structured_output_strategy=ProviderStrategy(
        schema=WeatherReport,
        strict=True  # 启用严格模式验证
    )
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "北京的天气如何？"}]
})

# 直接访问结构化数据
weather: WeatherReport = result["structured_response"]
print(f"温度: {weather.temperature}°C")
print(f"状况: {weather.condition}")
```

**支持的 schema 类型：**
- Pydantic 模型
- 数据类（dataclass）
- TypedDict
- JSON Schema

**strict 参数：**
- `True`：启用严格验证，确保输出完全符合 schema
- `False`：宽松模式，允许额外字段

#### 2. 工具调用策略（ToolStrategy）

用于不支持原生结构化输出的模型。

```python
from langchain.agents import create_agent, ToolStrategy
from pydantic import BaseModel, Field
from typing import Union

class MovieInfo(BaseModel):
    """电影信息"""
    title: str
    year: int
    director: str
    rating: float

class BookInfo(BaseModel):
    """图书信息"""
    title: str
    author: str
    isbn: str
    pages: int

# 支持 Union 类型（多种可能的输出格式）
OutputType = Union[MovieInfo, BookInfo]

agent = create_agent(
    model="gpt-3.5-turbo",
    tools=[],
    structured_output_strategy=ToolStrategy(
        schema=OutputType,
        tool_message_content="提取的信息",
        handle_errors=True  # 自动处理错误
    )
)
```

**配置参数：**
- `schema`：输出结构（支持 Pydantic、dataclass、TypedDict、JSON Schema、Union）
- `tool_message_content`：自定义工具消息内容
- `handle_errors`：错误处理行为

### 错误处理机制

系统自动处理两类常见错误：

#### 1. 多重输出错误

模型错误地返回多个结构化响应时触发重试。

```python
# 模型错误返回了 2 个结果，期望 1 个
# 系统会自动重试并要求模型只返回一个结果
```

#### 2. 模式验证错误

输出不符合预期 schema 时提供特定反馈。

```python
from langchain.agents import create_agent, ProviderStrategy
from pydantic import BaseModel, Field

class UserProfile(BaseModel):
    name: str = Field(..., min_length=1)
    age: int = Field(..., ge=0, le=150)
    email: str = Field(..., pattern=r'^[\w\.-]+@[\w\.-]+\.\w+$')

agent = create_agent(
    model="gpt-4",
    structured_output_strategy=ProviderStrategy(
        schema=UserProfile,
        strict=True
    )
)

# 如果模型返回的数据不符合验证规则
# 系统会自动重试并提供详细的错误信息
```

### 错误处理选项

```python
from langchain.agents import create_agent, ToolStrategy

# 选项 1：捕获所有错误
agent = create_agent(
    model="gpt-4",
    structured_output_strategy=ToolStrategy(
        schema=MySchema,
        handle_errors=True  # 捕获所有验证错误
    )
)

# 选项 2：自定义错误消息
agent = create_agent(
    model="gpt-4",
    structured_output_strategy=ToolStrategy(
        schema=MySchema,
        handle_errors="请检查输出格式，确保符合要求的结构"
    )
)

# 选项 3：只捕获特定异常
from pydantic import ValidationError

agent = create_agent(
    model="gpt-4",
    structured_output_strategy=ToolStrategy(
        schema=MySchema,
        handle_errors=ValidationError  # 只处理 Pydantic 验证错误
    )
)

# 选项 4：自定义错误处理函数
def custom_error_handler(error: Exception) -> str:
    """自定义错误处理逻辑"""
    if isinstance(error, ValidationError):
        return f"验证失败: {error.errors()}"
    return f"未知错误: {str(error)}"

agent = create_agent(
    model="gpt-4",
    structured_output_strategy=ToolStrategy(
        schema=MySchema,
        handle_errors=custom_error_handler
    )
)
```

### 代码示例

#### 1. 基础结构化输出

```python
from langchain.agents import create_agent, ProviderStrategy
from langchain.chat_models import init_chat_model
from pydantic import BaseModel, Field
from typing import List

class Article(BaseModel):
    """文章信息"""
    title: str = Field(..., description="文章标题")
    summary: str = Field(..., description="文章摘要", max_length=200)
    tags: List[str] = Field(..., description="文章标签")
    word_count: int = Field(..., description="字数统计", ge=0)
    sentiment: str = Field(..., description="情感倾向（积极/中性/消极）")

model = init_chat_model("gpt-4")
agent = create_agent(
    model=model,
    tools=[],
    structured_output_strategy=ProviderStrategy(
        schema=Article,
        strict=True
    )
)

# 调用代理
result = agent.invoke({
    "messages": [{
        "role": "user",
        "content": "分析这篇文章：《人工智能的未来发展趋势》..."
    }]
})

# 访问结构化输出
article: Article = result["structured_response"]
print(f"标题: {article.title}")
print(f"摘要: {article.summary}")
print(f"标签: {', '.join(article.tags)}")
print(f"字数: {article.word_count}")
print(f"情感: {article.sentiment}")

# 转换为 JSON
print(article.model_dump_json(indent=2))
```

#### 2. 复杂嵌套结构

```python
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime

class Address(BaseModel):
    """地址信息"""
    street: str
    city: str
    province: str
    postal_code: str

class OrderItem(BaseModel):
    """订单项"""
    product_id: str
    product_name: str
    quantity: int = Field(..., ge=1)
    price: float = Field(..., ge=0)

    @property
    def subtotal(self) -> float:
        return self.quantity * self.price

class Order(BaseModel):
    """订单信息"""
    order_id: str
    customer_name: str
    customer_email: str
    shipping_address: Address
    items: List[OrderItem]
    order_date: str
    status: str = Field(..., pattern="^(pending|processing|shipped|delivered)$")
    notes: Optional[str] = None

    @property
    def total_amount(self) -> float:
        return sum(item.subtotal for item in self.items)

agent = create_agent(
    model="gpt-4",
    tools=[],
    structured_output_strategy=ProviderStrategy(
        schema=Order,
        strict=True
    )
)

# 提取订单信息
result = agent.invoke({
    "messages": [{
        "role": "user",
        "content": """
        从以下文本提取订单信息：

        订单号：ORD-2025-001
        客户：张三 (zhang@email.com)
        地址：北京市朝阳区建国路 100 号，邮编 100000
        商品：
        - Python 编程书 x2，单价 89 元
        - 笔记本电脑 x1，单价 5999 元
        状态：处理中
        日期：2025-12-30
        """
    }]
})

order: Order = result["structured_response"]
print(f"订单号: {order.order_id}")
print(f"客户: {order.customer_name}")
print(f"总金额: ¥{order.total_amount}")
print(f"状态: {order.status}")
```

#### 3. Union 类型（多种可能输出）

```python
from pydantic import BaseModel
from typing import Union, Literal

class SuccessResponse(BaseModel):
    """成功响应"""
    status: Literal["success"]
    data: dict
    message: str

class ErrorResponse(BaseModel):
    """错误响应"""
    status: Literal["error"]
    error_code: str
    error_message: str
    details: dict = {}

Response = Union[SuccessResponse, ErrorResponse]

agent = create_agent(
    model="gpt-4",
    tools=[process_tool],
    structured_output_strategy=ToolStrategy(
        schema=Response,
        handle_errors=True
    )
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "处理这个请求"}]
})

response = result["structured_response"]

if isinstance(response, SuccessResponse):
    print(f"✓ 成功: {response.message}")
    print(f"数据: {response.data}")
else:
    print(f"✗ 错误 [{response.error_code}]: {response.error_message}")
    print(f"详情: {response.details}")
```

#### 4. 数据提取应用

```python
from pydantic import BaseModel, Field, validator
from typing import List
from datetime import date

class Person(BaseModel):
    """人物信息"""
    name: str
    age: int = Field(..., ge=0, le=150)
    occupation: str
    skills: List[str]

    @validator('name')
    def name_must_not_be_empty(cls, v):
        if not v.strip():
            raise ValueError('姓名不能为空')
        return v.strip()

class Company(BaseModel):
    """公司信息"""
    name: str
    founded_year: int
    industry: str
    employees: int = Field(..., ge=1)
    locations: List[str]

class NewsArticle(BaseModel):
    """新闻文章分析"""
    headline: str
    publication_date: str
    mentioned_people: List[Person]
    mentioned_companies: List[Company]
    key_events: List[str]
    summary: str = Field(..., max_length=500)

agent = create_agent(
    model="gpt-4",
    tools=[],
    structured_output_strategy=ProviderStrategy(
        schema=NewsArticle,
        strict=True
    )
)

# 提取新闻信息
news_text = """
标题：科技巨头宣布重大合作
日期：2025-12-30

OpenAI 今日宣布与微软达成战略合作。OpenAI CEO Sam Altman（40 岁，企业家，
专长：AI、创业）表示这将推动 AI 技术发展。

微软（成立于 1975 年，科技行业，员工 20 万人，总部在雷德蒙德）将投资 100 亿美元。
主要事件包括：签署合作协议、成立联合实验室、启动研究项目。
"""

result = agent.invoke({
    "messages": [{
        "role": "user",
        "content": f"从以下新闻中提取结构化信息：\n\n{news_text}"
    }]
})

article: NewsArticle = result["structured_response"]
print(f"标题: {article.headline}")
print(f"\n提及人物:")
for person in article.mentioned_people:
    print(f"  - {person.name}，{person.age}岁，{person.occupation}")
    print(f"    技能: {', '.join(person.skills)}")

print(f"\n提及公司:")
for company in article.mentioned_companies:
    print(f"  - {company.name}")
    print(f"    成立: {company.founded_year}，员工: {company.employees}")
```

#### 5. 使用 JSON Schema

```python
from langchain.agents import create_agent, ProviderStrategy

# JSON Schema 定义
user_schema = {
    "type": "object",
    "properties": {
        "user_id": {"type": "string"},
        "username": {"type": "string", "minLength": 3},
        "email": {"type": "string", "format": "email"},
        "age": {"type": "integer", "minimum": 0, "maximum": 150},
        "is_active": {"type": "boolean"},
        "roles": {
            "type": "array",
            "items": {"type": "string"}
        }
    },
    "required": ["user_id", "username", "email"],
    "additionalProperties": False
}

agent = create_agent(
    model="gpt-4",
    tools=[],
    structured_output_strategy=ProviderStrategy(
        schema=user_schema,
        strict=True
    )
)

result = agent.invoke({
    "messages": [{
        "role": "user",
        "content": "创建一个新用户：张三，邮箱 zhang@email.com，30 岁，管理员"
    }]
})

user_data = result["structured_response"]
print(user_data)
```

#### 6. 错误处理示例

```python
from pydantic import BaseModel, Field, ValidationError
from langchain.agents import create_agent, ProviderStrategy

class Product(BaseModel):
    """产品信息"""
    name: str = Field(..., min_length=1, max_length=100)
    price: float = Field(..., gt=0)  # 必须大于 0
    stock: int = Field(..., ge=0)    # 必须 >= 0
    category: str = Field(..., pattern="^(electronics|books|clothing|food)$")

def error_handler(error: Exception) -> str:
    """自定义错误处理"""
    if isinstance(error, ValidationError):
        errors = error.errors()
        messages = []
        for err in errors:
            field = err['loc'][0]
            msg = err['msg']
            messages.append(f"字段 '{field}' 错误: {msg}")
        return "验证失败，请修正以下问题：\n" + "\n".join(messages)
    return f"处理错误: {str(error)}"

agent = create_agent(
    model="gpt-4",
    tools=[],
    structured_output_strategy=ProviderStrategy(
        schema=Product,
        strict=True
    )
)

# 测试错误处理
try:
    result = agent.invoke({
        "messages": [{
            "role": "user",
            "content": "产品：手机，价格 -100 元，库存 10，类别：玩具"  # 包含错误
        }]
    })
except Exception as e:
    print(error_handler(e))
```

### 使用场景

1. **数据提取**
   - 从非结构化文本提取结构化数据
   - 信息提取和知识图谱构建
   - 表单自动填充

2. **API 集成**
   - 生成符合 API 要求的请求
   - 标准化 API 响应
   - 数据转换和映射

3. **分析报告**
   - 生成结构化分析结果
   - 自动化报告生成
   - 数据验证和质量检查

4. **对话系统**
   - 结构化意图识别
   - 槽位填充
   - 多轮对话状态管理

### 最佳实践

1. **选择合适的策略**
   - 优先使用 ProviderStrategy（性能更好）
   - 不支持原生结构化输出的模型使用 ToolStrategy
   - 复杂验证逻辑使用 Pydantic 模型

2. **设计良好的 Schema**
   - 提供清晰的字段描述
   - 使用适当的验证规则
   - 考虑可选字段和默认值

3. **错误处理**
   - 启用错误处理避免崩溃
   - 提供有意义的错误消息
   - 实现降级方案

4. **性能优化**
   - 避免过于复杂的嵌套结构
   - 使用 Union 类型处理多种可能输出
   - 缓存常用的 schema 定义

5. **验证和测试**
   - 测试边界情况
   - 验证输出数据的完整性
   - 监控验证失败率

---

## 参考链接

以下是本学习笔记参考的所有 LangChain Python 官方文档：

1. [LangChain Overview](https://docs.langchain.com/oss/python/langchain/overview.md) - LangChain 概述和核心概念
2. [Quickstart Guide](https://docs.langchain.com/oss/python/langchain/quickstart.md) - 快速开始指南
3. [Agents](https://docs.langchain.com/oss/python/langchain/agents.md) - 代理的创建和使用
4. [Models](https://docs.langchain.com/oss/python/langchain/models.md) - 模型集成和配置
5. [Messages](https://docs.langchain.com/oss/python/langchain/messages.md) - 消息类型和使用
6. [Tools](https://docs.langchain.com/oss/python/langchain/tools.md) - 工具定义和集成
7. [Short-term Memory](https://docs.langchain.com/oss/python/langchain/short-term-memory.md) - 短期记忆管理
8. [Streaming](https://docs.langchain.com/oss/python/langchain/streaming.md) - 流式输出处理
9. [Structured Output](https://docs.langchain.com/oss/python/langchain/structured-output.md) - 结构化输出配置

**官方资源：**
- [LangChain 官网](https://www.langchain.com/)
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [LangChain Python API 文档](https://api.python.langchain.com/)
- [LangSmith 调试平台](https://smith.langchain.com/)

**相关项目：**
- [LangGraph](https://github.com/langchain-ai/langgraph) - 低级代理编排框架
- [LangServe](https://github.com/langchain-ai/langserve) - 部署 LangChain 应用
- [LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates) - 应用模板

---

**文档版本信息：**
- 生成日期：2025-12-30
- LangChain 版本：基于最新官方文档
- 作者：学习笔记整理

---

## 总结

LangChain Python 提供了一套完整的工具和抽象，用于构建基于大语言模型的应用。通过本学习笔记，我们深入了解了：

1. **核心架构**：LangChain 构建在 LangGraph 之上，提供高层抽象
2. **代理系统**：基于 ReAct 模式的智能代理，能够推理和使用工具
3. **模型集成**：统一接口支持多个 AI 提供商
4. **消息系统**：标准化的消息类型支持多模态交互
5. **工具生态**：灵活的工具定义和运行时访问
6. **记忆管理**：短期记忆支持长对话和个性化
7. **流式处理**：多种流式模式改善用户体验
8. **结构化输出**：确保输出格式的一致性和可预测性

这些组件相互配合，使开发者能够快速构建生产级的 AI 应用。无论是简单的聊天机器人还是复杂的多代理系统，LangChain 都提供了必要的工具和最佳实践。
