# Pydantic AI æµå¼ä¼ è¾“

> æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨æµå¼ä¼ è¾“å®ç°å®æ—¶å“åº”ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸŒŠ ä¸ºä»€ä¹ˆéœ€è¦æµå¼ä¼ è¾“ï¼Ÿ

### é—®é¢˜ï¼šç­‰å¾…å®Œæ•´å“åº”

```python
# âŒ ä¼ ç»Ÿæ–¹å¼ï¼šç”¨æˆ·éœ€è¦ç­‰å¾…
agent = Agent('openai:gpt-4')
result = agent.run_sync('å†™ä¸€ç¯‡1000å­—çš„æ–‡ç« ')
print(result.data)  # ç”¨æˆ·ç­‰å¾…10-20ç§’æ‰çœ‹åˆ°ç»“æœ
```

### è§£å†³æ–¹æ¡ˆï¼šæµå¼è¾“å‡º

```python
# âœ… æµå¼ä¼ è¾“ï¼šå®æ—¶æ˜¾ç¤º
async with agent.run_stream('å†™ä¸€ç¯‡1000å­—çš„æ–‡ç« ') as stream:
    async for text in stream.stream_text():
        print(text, end='', flush=True)  # é€å­—æ˜¾ç¤º
```

**ä¼˜åŠ¿**ï¼š
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
- æ„ŸçŸ¥å“åº”æ›´å¿«
- é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆ
- å¯ä»¥æå‰ä¸­æ–­

## ğŸ“ åŸºç¡€æµå¼ä¼ è¾“

### æµå¼æ–‡æœ¬è¾“å‡º

```python
from pydantic_ai import Agent

agent = Agent('openai:gpt-4')

async def stream_example():
    async with agent.run_stream('ç”Ÿæˆä¸€æ®µé•¿æ–‡æœ¬') as stream:
        # é€å—æ¥æ”¶æ–‡æœ¬
        async for text_chunk in stream.stream_text():
            print(text_chunk, end='', flush=True)

        # è·å–æœ€ç»ˆç»“æœ
        result = await stream.get_result()
        print(f"\n\næ€»tokenæ•°: {result.usage().total_tokens}")

# è¿è¡Œ
import asyncio
asyncio.run(stream_example())
```

### åŒæ­¥æµå¼ä¼ è¾“

è™½ç„¶åº•å±‚æ˜¯å¼‚æ­¥çš„ï¼Œä½†å¯ä»¥åœ¨åŒæ­¥ä»£ç ä¸­ä½¿ç”¨ï¼š

```python
def sync_stream():
    # æ³¨æ„ï¼šè¿™ä¼šå†…éƒ¨åˆ›å»ºäº‹ä»¶å¾ªç¯
    with agent.run_stream_sync('ç”Ÿæˆæ–‡æœ¬') as stream:
        for text in stream.stream_text_sync():
            print(text, end='', flush=True)

        result = stream.get_result_sync()
```

## ğŸ—ï¸ æµå¼ç»“æ„åŒ–è¾“å‡º

### éƒ¨åˆ†æ•°æ®æµ

```python
from pydantic import BaseModel

class Story(BaseModel):
    title: str
    chapters: list[str]
    conclusion: str

agent = Agent('openai:gpt-4', output_type=Story)

async def stream_structured():
    async with agent.run_stream('å†™ä¸€ä¸ªä¸‰ç« èŠ‚çš„æ•…äº‹') as stream:
        # æµå¼æ¥æ”¶éƒ¨åˆ†è§£æçš„æ•°æ®
        async for partial_story in stream.stream():
            if partial_story.title:
                print(f"æ ‡é¢˜: {partial_story.title}")

            if partial_story.chapters:
                print(f"å½“å‰ç« èŠ‚æ•°: {len(partial_story.chapters)}")
                if len(partial_story.chapters) > 0:
                    print(f"æœ€æ–°ç« èŠ‚: {partial_story.chapters[-1][:50]}...")

        # æœ€ç»ˆå®Œæ•´æ•°æ®
        final_story = await stream.get_result()
        print(f"\n\nå®Œæ•´æ•…äº‹ï¼š")
        print(f"æ ‡é¢˜ï¼š{final_story.data.title}")
        print(f"ç« èŠ‚æ•°ï¼š{len(final_story.data.chapters)}")
```

### åˆ—è¡¨æ•°æ®æµ

```python
class Item(BaseModel):
    name: str
    price: float

agent = Agent('openai:gpt-4', output_type=list[Item])

async def stream_list():
    async with agent.run_stream('åˆ—å‡º10ä¸ªå•†å“') as stream:
        async for partial_list in stream.stream():
            print(f"å·²ç”Ÿæˆ {len(partial_list)} ä¸ªå•†å“")
            if partial_list:
                latest = partial_list[-1]
                print(f"  æœ€æ–°: {latest.name} - Â¥{latest.price}")
```

## ğŸ›ï¸ äº‹ä»¶æµ

### ç›‘å¬æ‰€æœ‰äº‹ä»¶

```python
from pydantic_ai import Agent

agent = Agent('openai:gpt-4')

async def handle_events():
    async for event in agent.run_stream_events('æ‰§è¡Œå¤æ‚ä»»åŠ¡'):
        if event.type == 'text':
            # æ–‡æœ¬ç”Ÿæˆäº‹ä»¶
            print(event.data, end='', flush=True)

        elif event.type == 'tool_call':
            # å·¥å…·è°ƒç”¨äº‹ä»¶
            print(f"\n[è°ƒç”¨å·¥å…·: {event.tool_name}]")
            print(f"å‚æ•°: {event.args}")

        elif event.type == 'tool_return':
            # å·¥å…·è¿”å›äº‹ä»¶
            print(f"[å·¥å…·ç»“æœ: {event.result}]")

        elif event.type == 'thinking':
            # æ€è€ƒè¿‡ç¨‹ï¼ˆéƒ¨åˆ†æ¨¡å‹æ”¯æŒï¼‰
            print(f"\n[æ€è€ƒ: {event.data}]")

        elif event.type == 'complete':
            # å®Œæˆäº‹ä»¶
            print(f"\n[å®Œæˆ]")
            print(f"æœ€ç»ˆç»“æœ: {event.data}")
```

### äº‹ä»¶ç±»å‹

| äº‹ä»¶ç±»å‹ | è¯´æ˜ | æ•°æ® |
|---------|------|------|
| `text` | æ–‡æœ¬ç”Ÿæˆ | æ–‡æœ¬å— |
| `tool_call` | å·¥å…·è°ƒç”¨å¼€å§‹ | å·¥å…·åã€å‚æ•° |
| `tool_return` | å·¥å…·è¿”å› | è¿”å›å€¼ |
| `thinking` | æ€è€ƒè¿‡ç¨‹ | æ€è€ƒå†…å®¹ |
| `complete` | ç”Ÿæˆå®Œæˆ | æœ€ç»ˆç»“æœ |

## ğŸ’» å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: èŠå¤©ç•Œé¢

```python
async def chat_interface():
    """æ¨¡æ‹ŸèŠå¤©ç•Œé¢çš„å®æ—¶å“åº”"""
    agent = Agent('openai:gpt-4')

    while True:
        user_input = input("\nä½ : ")
        if user_input.lower() in ['quit', 'exit']:
            break

        print("AI: ", end='', flush=True)

        async with agent.run_stream(user_input) as stream:
            full_response = []

            async for text in stream.stream_text():
                print(text, end='', flush=True)
                full_response.append(text)

            # ä¿å­˜å®Œæ•´å“åº”ç”¨äºå†å²
            response_text = ''.join(full_response)

        print()  # æ¢è¡Œ
```

### ç¤ºä¾‹ 2: è¿›åº¦æŒ‡ç¤ºå™¨

```python
async def generate_with_progress():
    """æ˜¾ç¤ºç”Ÿæˆè¿›åº¦"""
    from pydantic import BaseModel

    class Article(BaseModel):
        title: str
        sections: list[str]

    agent = Agent('openai:gpt-4', output_type=Article)

    print("ç”Ÿæˆæ–‡ç« ...")

    async with agent.run_stream('å†™ä¸€ç¯‡åŒ…å«5ä¸ªç« èŠ‚çš„æ–‡ç« ') as stream:
        async for partial in stream.stream():
            if partial.title:
                print(f"\râœ“ æ ‡é¢˜å·²ç”Ÿæˆ", end='', flush=True)

            if partial.sections:
                count = len(partial.sections)
                print(f"\râœ“ æ ‡é¢˜ | ç« èŠ‚ {count}/5", end='', flush=True)

        result = await stream.get_result()
        print(f"\nâœ“ å®Œæˆï¼")
        return result.data
```

### ç¤ºä¾‹ 3: æµå¼æ‘˜è¦

```python
async def streaming_summarizer():
    """å®æ—¶æ€»ç»“é•¿æ–‡æœ¬"""
    agent = Agent('openai:gpt-4')

    long_text = """..."""  # å¾ˆé•¿çš„æ–‡æœ¬

    print("æ­£åœ¨ç”Ÿæˆæ‘˜è¦...\n")

    buffer = []
    async with agent.run_stream(
        f'è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š\n{long_text}'
    ) as stream:
        async for text in stream.stream_text():
            buffer.append(text)
            print(text, end='', flush=True)

            # æ¯100å­—ç¬¦å¤„ç†ä¸€æ¬¡
            if len(''.join(buffer)) >= 100:
                await process_chunk(''.join(buffer))
                buffer = []

        # å¤„ç†å‰©ä½™éƒ¨åˆ†
        if buffer:
            await process_chunk(''.join(buffer))

async def process_chunk(chunk: str):
    """å¤„ç†æ–‡æœ¬å—"""
    # ä¾‹å¦‚ï¼šå®æ—¶ä¿å­˜åˆ°æ•°æ®åº“
    pass
```

## ğŸ”„ æ§åˆ¶æµå¼ä¼ è¾“

### æå‰ç»ˆæ­¢

```python
async def cancellable_stream():
    """å¯å–æ¶ˆçš„æµå¼ä¼ è¾“"""
    import asyncio

    agent = Agent('openai:gpt-4')

    async with agent.run_stream('ç”Ÿæˆå¾ˆé•¿çš„æ–‡æœ¬') as stream:
        try:
            word_count = 0
            async for text in stream.stream_text():
                print(text, end='', flush=True)
                word_count += len(text.split())

                # è¾¾åˆ°ç›®æ ‡å­—æ•°ååœæ­¢
                if word_count >= 200:
                    print("\n\n[å·²è¾¾åˆ°ç›®æ ‡å­—æ•°ï¼Œåœæ­¢ç”Ÿæˆ]")
                    break

        except asyncio.CancelledError:
            print("\n[ç”¨æˆ·å–æ¶ˆ]")
```

### è¶…æ—¶æ§åˆ¶

```python
async def stream_with_timeout():
    """å¸¦è¶…æ—¶çš„æµå¼ä¼ è¾“"""
    import asyncio

    agent = Agent('openai:gpt-4')

    try:
        async with asyncio.timeout(10):  # 10ç§’è¶…æ—¶
            async with agent.run_stream('ç”Ÿæˆæ–‡æœ¬') as stream:
                async for text in stream.stream_text():
                    print(text, end='', flush=True)

    except asyncio.TimeoutError:
        print("\n[è¶…æ—¶]")
```

## ğŸ¨ UI é›†æˆ

### Web åº”ç”¨ï¼ˆFastAPI + SSEï¼‰

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()
agent = Agent('openai:gpt-4')

@app.get("/stream")
async def stream_endpoint(prompt: str):
    """Server-Sent Events ç«¯ç‚¹"""

    async def event_generator():
        async with agent.run_stream(prompt) as stream:
            async for text in stream.stream_text():
                # SSE æ ¼å¼
                yield f"data: {text}\n\n"

            yield "data: [DONE]\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )
```

### å‘½ä»¤è¡Œè¿›åº¦æ¡

```python
from tqdm import tqdm

async def stream_with_progress_bar():
    """å¸¦è¿›åº¦æ¡çš„æµå¼ä¼ è¾“"""
    agent = Agent('openai:gpt-4')

    # ä¼°è®¡å¤§çº¦ä¼šç”Ÿæˆçš„tokenæ•°
    estimated_tokens = 500

    with tqdm(total=estimated_tokens, desc="ç”Ÿæˆä¸­") as pbar:
        token_count = 0

        async with agent.run_stream('ç”Ÿæˆæ–‡æœ¬') as stream:
            async for text in stream.stream_text():
                # ä¼°ç®—tokenæ•°ï¼ˆç²—ç•¥ï¼‰
                new_tokens = len(text.split())
                token_count += new_tokens
                pbar.update(new_tokens)

            result = await stream.get_result()
            actual_tokens = result.usage().total_tokens
            pbar.total = actual_tokens
            pbar.refresh()
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç¼“å†²è¾“å‡º

```python
async def buffered_stream():
    """ç¼“å†²è¾“å‡ºï¼Œå‡å°‘æ¸²æŸ“æ¬¡æ•°"""
    buffer = []
    buffer_size = 10  # æ¯10ä¸ªå­—ç¬¦è¾“å‡ºä¸€æ¬¡

    async with agent.run_stream('ç”Ÿæˆæ–‡æœ¬') as stream:
        async for text in stream.stream_text():
            buffer.append(text)

            if len(''.join(buffer)) >= buffer_size:
                print(''.join(buffer), end='', flush=True)
                buffer = []

        # è¾“å‡ºå‰©ä½™å†…å®¹
        if buffer:
            print(''.join(buffer), end='', flush=True)
```

### 2. é”™è¯¯å¤„ç†

```python
async def robust_stream():
    """å¥å£®çš„æµå¼ä¼ è¾“"""
    try:
        async with agent.run_stream('ç”Ÿæˆæ–‡æœ¬') as stream:
            async for text in stream.stream_text():
                print(text, end='', flush=True)

            result = await stream.get_result()

    except Exception as e:
        print(f"\n[é”™è¯¯: {e}]")
        # å¯ä»¥é€‰æ‹©é‡è¯•æˆ–é™çº§
```

### 3. ä¿å­˜å®Œæ•´å“åº”

```python
async def save_stream():
    """è¾¹æµå¼æ˜¾ç¤ºè¾¹ä¿å­˜"""
    full_text = []

    async with agent.run_stream('ç”Ÿæˆæ–‡æœ¬') as stream:
        async for text in stream.stream_text():
            print(text, end='', flush=True)
            full_text.append(text)

        # ä¿å­˜å®Œæ•´å“åº”
        complete_text = ''.join(full_text)
        await save_to_database(complete_text)
```

## ğŸ“š ä¸‹ä¸€æ­¥

- [09_å›¾å·¥ä½œæµ.md](./09_å›¾å·¥ä½œæµ.md) - å¤æ‚å·¥ä½œæµ
- [14_æœ€ä½³å®è·µ.md](./14_æœ€ä½³å®è·µ.md) - æ€§èƒ½ä¼˜åŒ–

## ğŸ”— å‚è€ƒèµ„æº

- [å®˜æ–¹æ–‡æ¡£ - Streaming](https://ai.pydantic.dev/agents/#streaming)
- [FastAPI SSE](https://fastapi.tiangolo.com/advanced/custom-response/)
