# Pydantic AI Agent ç³»ç»Ÿè¯¦è§£

> æœ¬æ–‡æ¡£æ·±å…¥è®²è§£ Agent çš„åˆ›å»ºã€é…ç½®ã€è¿è¡Œå’Œç®¡ç†ï¼Œå¸®åŠ©ä½ å……åˆ†å‘æŒ¥ Agent çš„èƒ½åŠ›ã€‚

## ğŸ“‹ ç›®å½•

- [Agent çš„åˆ›å»º](#agent-çš„åˆ›å»º)
- [System Prompt å’Œ Instructions](#system-prompt-å’Œ-instructions)
- [è¿è¡Œæ–¹å¼è¯¦è§£](#è¿è¡Œæ–¹å¼è¯¦è§£)
- [æ¶ˆæ¯å†å²ç®¡ç†](#æ¶ˆæ¯å†å²ç®¡ç†)
- [é”™è¯¯å¤„ç†å’Œé‡è¯•](#é”™è¯¯å¤„ç†å’Œé‡è¯•)
- [å…ƒæ•°æ®å’Œè¿½è¸ª](#å…ƒæ•°æ®å’Œè¿½è¸ª)
- [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)

## ğŸ—ï¸ Agent çš„åˆ›å»º

### åŸºç¡€åˆ›å»º

```python
from pydantic_ai import Agent

# æœ€ç®€å•çš„ Agent
agent = Agent('openai:gpt-4')

# å¸¦ç³»ç»Ÿæç¤ºçš„ Agent
agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ã€‚'
)

# å®Œæ•´é…ç½®çš„ Agent
from pydantic_ai import Agent, ModelSettings, UsageLimits
from pydantic import BaseModel


class OutputSchema(BaseModel):
    answer: str
    confidence: float


agent = Agent(
    model='anthropic:claude-3-5-sonnet-20241022',
    deps_type=MyDependencies,
    output_type=OutputSchema,
    system_prompt='ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚',
    tools=[tool1, tool2, tool3],
    retries=3,
    model_settings=ModelSettings(
        temperature=0.7,
        max_tokens=2000,
        timeout=60
    ),
    usage_limits=UsageLimits(
        request_limit=10,
        tool_calls_limit=5
    )
)
```

### æ„é€ å‚æ•°è¯¦è§£

#### `model` - æ¨¡å‹é€‰æ‹©

æ ¼å¼ï¼š`provider:model_name`

```python
# OpenAI
Agent('openai:gpt-4')
Agent('openai:gpt-4-turbo')
Agent('openai:gpt-3.5-turbo')

# Anthropic
Agent('anthropic:claude-3-5-sonnet-20241022')
Agent('anthropic:claude-3-opus-20240229')

# Google
Agent('google:gemini-1.5-pro')
Agent('google:gemini-1.5-flash')

# Groq (å¿«é€Ÿä¸”å…è´¹)
Agent('groq:llama3-70b-8192')
Agent('groq:mixtral-8x7b-32768')
```

#### `deps_type` - ä¾èµ–ç±»å‹

æŒ‡å®š `RunContext` çš„æ³›å‹ç±»å‹ï¼š

```python
from dataclasses import dataclass


@dataclass
class DatabaseDeps:
    db_url: str
    api_key: str


agent = Agent(
    'openai:gpt-4',
    deps_type=DatabaseDeps
)

# ç±»å‹å®‰å…¨ï¼šctx.deps çš„ç±»å‹æ˜¯ DatabaseDeps
@agent.tool
def query_db(ctx: RunContext[DatabaseDeps], query: str) -> str:
    # IDE ä¼šæä¾›è‡ªåŠ¨è¡¥å…¨
    url = ctx.deps.db_url
    key = ctx.deps.api_key
    return execute_query(url, key, query)
```

#### `output_type` - è¾“å‡ºç±»å‹

é»˜è®¤ä¸º `str`ï¼Œå¯ä»¥æ˜¯ä»»ä½• Pydantic æ¨¡å‹ï¼š

```python
# ç®€å•ç±»å‹
agent = Agent('openai:gpt-4', output_type=int)
result = agent.run_sync('1+1ç­‰äºå¤šå°‘ï¼Ÿ')
print(result.data)  # 2 (int ç±»å‹)

# Pydantic æ¨¡å‹
class Person(BaseModel):
    name: str
    age: int
    occupation: str


agent = Agent('openai:gpt-4', output_type=Person)
result = agent.run_sync('ä»‹ç»ä¸€ä¸‹çˆ±å› æ–¯å¦')
print(result.data.name)  # "Albert Einstein"
```

#### `retries` - é‡è¯•æ¬¡æ•°

LLM å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°ï¼š

```python
agent = Agent(
    'openai:gpt-4',
    retries=3  # å¤±è´¥åæœ€å¤šé‡è¯•3æ¬¡
)

# å¯ä»¥åœ¨è¿è¡Œæ—¶è¦†ç›–
result = agent.run_sync('æç¤º', retries=5)
```

#### `model_settings` - æ¨¡å‹è®¾ç½®

```python
from pydantic_ai import ModelSettings

agent = Agent(
    'openai:gpt-4',
    model_settings=ModelSettings(
        temperature=0.7,        # åˆ›é€ æ€§ (0-2)
        max_tokens=2000,        # æœ€å¤§ç”Ÿæˆé•¿åº¦
        timeout=30,             # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        top_p=0.9,             # æ ¸é‡‡æ ·
        frequency_penalty=0.5,  # é¢‘ç‡æƒ©ç½š
        presence_penalty=0.5,   # å­˜åœ¨æƒ©ç½š
    )
)
```

#### `usage_limits` - ä½¿ç”¨é™åˆ¶

```python
from pydantic_ai import UsageLimits

agent = Agent(
    'openai:gpt-4',
    usage_limits=UsageLimits(
        response_tokens_limit=10000,  # æœ€å¤§å“åº”tokenæ•°
        request_limit=50,             # æœ€å¤§è¯·æ±‚æ¬¡æ•°
        tool_calls_limit=20,          # æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
    )
)
```

## ğŸ’¬ System Prompt å’Œ Instructions

### é™æ€ System Prompt

```python
agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ï¼Œæ“…é•¿æ•°æ®åˆ†æå’Œå¯è§†åŒ–ã€‚'
)
```

### åŠ¨æ€ System Prompt

ä½¿ç”¨è£…é¥°å™¨å®šä¹‰åŠ¨æ€æç¤ºï¼š

```python
from pydantic_ai import Agent, RunContext


@dataclass
class UserContext:
    user_id: str
    user_level: str  # "beginner", "intermediate", "expert"


agent = Agent('openai:gpt-4', deps_type=UserContext)


@agent.system_prompt
def get_system_prompt(ctx: RunContext[UserContext]) -> str:
    level = ctx.deps.user_level

    prompts = {
        "beginner": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„å¯¼å¸ˆï¼Œç”¨ç®€å•çš„è¯­è¨€è§£é‡Šæ¦‚å¿µã€‚",
        "intermediate": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¾é—®ï¼Œæä¾›è¯¦ç»†çš„æŠ€æœ¯å»ºè®®ã€‚",
        "expert": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ï¼Œå¯ä»¥æ·±å…¥æ¢è®¨é«˜çº§ä¸»é¢˜ã€‚"
    }

    return prompts.get(level, prompts["beginner"])


# ä½¿ç”¨
result = agent.run_sync(
    'è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ',
    deps=UserContext(user_id='123', user_level='beginner')
)
```

### å¼‚æ­¥åŠ¨æ€ System Prompt

```python
@agent.system_prompt
async def get_system_prompt(ctx: RunContext[UserContext]) -> str:
    # ä»æ•°æ®åº“å¼‚æ­¥åŠ è½½ç”¨æˆ·åå¥½
    preferences = await load_user_preferences(ctx.deps.user_id)

    return f'æ ¹æ®ç”¨æˆ·åå¥½ {preferences} å®šåˆ¶å›ç­”ã€‚'
```

### Static Instructions

```python
agent = Agent(
    'openai:gpt-4',
    instructions='æå–æ–‡æœ¬ä¸­çš„å…³é”®ä¿¡æ¯ã€‚'
)
```

### åŠ¨æ€ Instructions

```python
@agent.instructions
def get_instructions(ctx: RunContext[MyDeps]) -> str:
    task_type = ctx.deps.task_type

    if task_type == 'summarize':
        return 'æ€»ç»“æ–‡æœ¬çš„æ ¸å¿ƒè¦ç‚¹ã€‚'
    elif task_type == 'translate':
        return 'å°†æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ã€‚'
    else:
        return 'åˆ†ææ–‡æœ¬æƒ…æ„Ÿã€‚'
```

### System Prompt vs Instructions

| ç‰¹æ€§ | System Prompt | Instructions |
|------|--------------|-------------|
| ä¿ç•™å†å² | âœ… æ˜¯ | âŒ å¦ |
| æ¨èåœºæ™¯ | å®šä¹‰æŒä¹…èº«ä»½ | å®šä¹‰å…·ä½“ä»»åŠ¡ |
| ä½¿ç”¨é¢‘ç‡ | è¾ƒå°‘ | æ¨è |

**æ¨èåšæ³•**ï¼š
- å¤§å¤šæ•°æƒ…å†µä½¿ç”¨ `instructions`
- åªåœ¨éœ€è¦ä¿ç•™å†å²ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨ `system_prompt`

## ğŸƒ è¿è¡Œæ–¹å¼è¯¦è§£

### 1. run() - å¼‚æ­¥è¿è¡Œ

**è¿”å›**: `RunResult`

```python
async def process():
    result = await agent.run('ç”¨æˆ·è¾“å…¥')

    # è®¿é—®ç»“æœ
    print(result.data)              # è¾“å‡ºæ•°æ®
    print(result.usage())           # Tokenä½¿ç”¨
    print(result.cost())            # ä¼°ç®—æˆæœ¬
    print(result.all_messages())    # å®Œæ•´æ¶ˆæ¯å†å²
    print(result.timestamp())       # æ—¶é—´æˆ³
```

**RunResult å±æ€§**ï¼š

```python
result.data                 # è¾“å‡ºæ•°æ®ï¼ˆç±»å‹ä¸º output_typeï¼‰
result.usage()             # UsageInfo å¯¹è±¡
result.cost()              # Optional[Cost] å¯¹è±¡
result.all_messages()      # æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
result.new_messages()      # æ–°æ¶ˆæ¯ï¼ˆç”¨äºå†å²ï¼‰
result.timestamp()         # è¿è¡Œæ—¶é—´æˆ³
```

### 2. run_sync() - åŒæ­¥è¿è¡Œ

```python
result = agent.run_sync('ç”¨æˆ·è¾“å…¥')

# ç­‰ä»·äº
import asyncio
result = asyncio.run(agent.run('ç”¨æˆ·è¾“å…¥'))
```

**æ³¨æ„äº‹é¡¹**ï¼š
- åº•å±‚ä»æ˜¯å¼‚æ­¥
- ä¼šåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ï¼ˆå¦‚æœæ²¡æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼‰
- ä¸é€‚åˆåœ¨å¼‚æ­¥å‡½æ•°ä¸­è°ƒç”¨

### 3. run_stream() - æµå¼ä¼ è¾“

**è¿”å›**: å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
async def stream_response():
    async with agent.run_stream('ç”Ÿæˆé•¿æ–‡æœ¬') as stream:
        # é€æ–‡æœ¬æµå¼è¾“å‡º
        async for text in stream.stream_text():
            print(text, end='', flush=True)

        # è·å–æœ€ç»ˆç»“æœ
        result = await stream.get_result()
        print(f"\n\næ€»tokenæ•°: {result.usage().total_tokens}")
```

**æµå¼ç»“æ„åŒ–è¾“å‡º**ï¼š

```python
class Story(BaseModel):
    title: str
    chapters: list[str]


agent = Agent('openai:gpt-4', output_type=Story)


async def stream_story():
    async with agent.run_stream('å†™ä¸€ä¸ªçŸ­ç¯‡æ•…äº‹') as stream:
        # æµå¼æ¥æ”¶éƒ¨åˆ†è§£æçš„æ•°æ®
        async for partial in stream.stream():
            if partial.title:
                print(f"æ ‡é¢˜: {partial.title}")
            if partial.chapters:
                print(f"å½“å‰ç« èŠ‚æ•°: {len(partial.chapters)}")

        # æœ€ç»ˆå®Œæ•´æ•°æ®
        final = await stream.get_result()
        print(f"\nå®Œæ•´æ•…äº‹: {final.data}")
```

### 4. run_stream_events() - äº‹ä»¶æµ

**è¿”å›**: `AsyncIterator[AgentStreamEvent]`

```python
async def handle_events():
    async for event in agent.run_stream_events('å¤„ç†å¤æ‚ä»»åŠ¡'):
        if event.type == 'text':
            # æ–‡æœ¬ç”Ÿæˆäº‹ä»¶
            print(event.data, end='')

        elif event.type == 'tool_call':
            # å·¥å…·è°ƒç”¨äº‹ä»¶
            print(f"\nè°ƒç”¨å·¥å…·: {event.tool_name}")
            print(f"å‚æ•°: {event.args}")

        elif event.type == 'tool_return':
            # å·¥å…·è¿”å›äº‹ä»¶
            print(f"å·¥å…·ç»“æœ: {event.result}")

        elif event.type == 'thinking':
            # æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            print(f"æ€è€ƒ: {event.data}")
```

**äº‹ä»¶ç±»å‹**ï¼š
- `text`: æ–‡æœ¬ç”Ÿæˆ
- `tool_call`: å·¥å…·è°ƒç”¨
- `tool_return`: å·¥å…·è¿”å›
- `thinking`: æ€è€ƒè¿‡ç¨‹
- `complete`: å®Œæˆ

### 5. iter() - å›¾è¿­ä»£

**è¿”å›**: `AsyncIterator[GraphNode]`

ä½çº§ APIï¼Œç”¨äºå›¾å·¥ä½œæµï¼š

```python
async def graph_iteration():
    async for node in agent.iter('æç¤º'):
        print(f"èŠ‚ç‚¹ç±»å‹: {node.type}")

        if node.type == 'tool_call':
            print(f"è°ƒç”¨å·¥å…·: {node.tool_name}")
            # å¯ä»¥å¹²é¢„æˆ–ä¿®æ”¹

        elif node.type == 'complete':
            print(f"æœ€ç»ˆç»“æœ: {node.data}")
```

## ğŸ“œ æ¶ˆæ¯å†å²ç®¡ç†

### æ„å»ºå¯¹è¯

```python
# åˆå§‹å¯¹è¯
result1 = agent.run_sync('æˆ‘å«å¼ ä¸‰')

# ç»§ç»­å¯¹è¯ - ä¼ é€’å†å²
result2 = agent.run_sync(
    'æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ',
    message_history=result1.new_messages()
)
# è¾“å‡º: ä½ å«å¼ ä¸‰ã€‚

# ç»§ç»­å¯¹è¯
result3 = agent.run_sync(
    'æ€»ç»“æˆ‘ä»¬çš„å¯¹è¯',
    message_history=result2.new_messages()
)
```

### åˆå¹¶å¤šè½®å†å²

```python
from pydantic_ai.messages import ModelMessage

# æ”¶é›†æ‰€æœ‰å†å²
history = []
history.extend(result1.new_messages())
history.extend(result2.new_messages())

# ç»§ç»­å¯¹è¯
result3 = agent.run_sync(
    'æ–°çš„é—®é¢˜',
    message_history=history
)
```

### è‡ªå®šä¹‰æ¶ˆæ¯

```python
from pydantic_ai.messages import UserMessage, SystemMessage

# æ„é€ è‡ªå®šä¹‰å†å²
custom_history = [
    SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªå†å²å­¦å®¶'),
    UserMessage(content='ä»‹ç»ç§¦å§‹çš‡', timestamp=...),
    # ... æ›´å¤šæ¶ˆæ¯
]

result = agent.run_sync(
    'ä»–ç»Ÿä¸€äº†ä»€ä¹ˆï¼Ÿ',
    message_history=custom_history
)
```

## ğŸ”„ é”™è¯¯å¤„ç†å’Œé‡è¯•

### ModelRetry - è‡ªæˆ‘ä¿®æ­£

```python
from pydantic_ai import ModelRetry


@agent.output_validator
def validate_output(ctx: RunContext[None], output: MyOutput) -> MyOutput:
    if output.confidence < 0.8:
        # è§¦å‘é‡è¯•ï¼Œè®©æ¨¡å‹æ”¹è¿›
        raise ModelRetry('ç½®ä¿¡åº¦å¤ªä½ï¼Œè¯·æä¾›æ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚')

    return output
```

**ModelRetry çš„å·¥ä½œåŸç†**ï¼š
1. éªŒè¯å™¨æŠ›å‡º `ModelRetry`
2. é”™è¯¯æ¶ˆæ¯å‘é€ç»™ LLM
3. LLM é‡æ–°ç”Ÿæˆå“åº”
4. é‡å¤ç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°é‡è¯•é™åˆ¶

### æ•è·è¿è¡Œæ¶ˆæ¯

```python
from pydantic_ai import capture_run_messages


with capture_run_messages() as messages:
    try:
        result = agent.run_sync('å¯èƒ½å¤±è´¥çš„è¯·æ±‚')
    except Exception as e:
        # æ£€æŸ¥å¤±è´¥çš„æ¶ˆæ¯
        print(f"é”™è¯¯: {e}")
        print(f"æ¶ˆæ¯å†å²: {messages}")
        # å¯ä»¥ç”¨äºè°ƒè¯•
```

### è‡ªå®šä¹‰é‡è¯•é€»è¾‘

```python
from tenacity import retry, stop_after_attempt, wait_exponential


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
async def robust_run(prompt: str):
    try:
        return await agent.run(prompt)
    except Exception as e:
        print(f"é‡è¯•ä¸­... é”™è¯¯: {e}")
        raise
```

## ğŸ·ï¸ å…ƒæ•°æ®å’Œè¿½è¸ª

### é™æ€å…ƒæ•°æ®

```python
agent = Agent(
    'openai:gpt-4',
    metadata={
        'app_version': '1.0.0',
        'environment': 'production'
    }
)
```

### åŠ¨æ€å…ƒæ•°æ®

```python
from pydantic_ai import Agent, RunContext


@dataclass
class TenantDeps:
    tenant_id: str
    user_id: str


agent = Agent('openai:gpt-4', deps_type=TenantDeps)


@agent.metadata
def get_metadata(ctx: RunContext[TenantDeps]) -> dict[str, str]:
    return {
        'tenant_id': ctx.deps.tenant_id,
        'user_id': ctx.deps.user_id,
        'request_time': str(datetime.now())
    }
```

**å…ƒæ•°æ®çš„ç”¨é€”**ï¼š
- åœ¨ Logfire ä¸­è¿½è¸ª
- æŒ‰ç§Ÿæˆ·/ç”¨æˆ·åˆ†ç»„
- æ€§èƒ½åˆ†æ
- æˆæœ¬å½’å› 

## âš™ï¸ é«˜çº§é…ç½®

### è¦†ç›–é…ç½®

Agent çš„é…ç½®å¯ä»¥åœ¨å¤šä¸ªå±‚çº§è¦†ç›–ï¼š

```python
# 1. Agent çº§åˆ«
agent = Agent(
    'openai:gpt-4',
    model_settings=ModelSettings(temperature=0.5),
    retries=2
)

# 2. è¿è¡Œæ—¶è¦†ç›–
result = agent.run_sync(
    'æç¤º',
    model_settings=ModelSettings(temperature=0.9),  # è¦†ç›–
    retries=5  # è¦†ç›–
)
```

### ä½¿ç”¨ override() ä¸Šä¸‹æ–‡

ç”¨äºæµ‹è¯•æˆ–ä¸´æ—¶ä¿®æ”¹ï¼š

```python
with agent.override(
    model='openai:gpt-3.5-turbo',  # ä¸´æ—¶ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
    deps=test_deps
):
    result = agent.run_sync('æµ‹è¯•æç¤º')
```

### æ¡ä»¶é…ç½®

```python
import os

# æ ¹æ®ç¯å¢ƒä½¿ç”¨ä¸åŒæ¨¡å‹
if os.getenv('ENVIRONMENT') == 'production':
    model = 'openai:gpt-4'
    temperature = 0.3
else:
    model = 'openai:gpt-3.5-turbo'
    temperature = 0.7

agent = Agent(
    model,
    model_settings=ModelSettings(temperature=temperature)
)
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å…¨å±€ Agent å®ä¾‹

```python
# âœ… æ¨èï¼šæ¨¡å—çº§åˆ«å®šä¹‰
support_agent = Agent('openai:gpt-4', system_prompt='å®¢æœåŠ©æ‰‹')
analyst_agent = Agent('openai:gpt-4', system_prompt='æ•°æ®åˆ†æå¸ˆ')

def handle_support(query: str):
    return support_agent.run_sync(query)


def analyze_data(data: str):
    return analyst_agent.run_sync(data)
```

### 2. ä½¿ç”¨ç±»å‹æç¤º

```python
from typing import TypedDict


class MyDeps(TypedDict):
    db_url: str
    api_key: str


class MyOutput(BaseModel):
    answer: str


# âœ… å®Œæ•´ç±»å‹æ³¨è§£
agent: Agent[MyDeps, MyOutput] = Agent(
    'openai:gpt-4',
    deps_type=MyDeps,
    output_type=MyOutput
)
```

### 3. è®¾ç½®åˆç†çš„é™åˆ¶

```python
agent = Agent(
    'openai:gpt-4',
    usage_limits=UsageLimits(
        request_limit=10,      # é˜²æ­¢æ— é™å¾ªç¯
        tool_calls_limit=5,    # é™åˆ¶å·¥å…·è°ƒç”¨
        response_tokens_limit=5000  # æ§åˆ¶æˆæœ¬
    ),
    retries=2  # ä¸è¦è¿‡åº¦é‡è¯•
)
```

### 4. ä¼˜é›…å¤„ç†é”™è¯¯

```python
from pydantic_ai.exceptions import UsageLimitExceeded, ModelRetryError

try:
    result = await agent.run(user_input)
except UsageLimitExceeded as e:
    print(f"è¾¾åˆ°ä½¿ç”¨é™åˆ¶: {e}")
except ModelRetryError as e:
    print(f"é‡è¯•å¤±è´¥: {e}")
except Exception as e:
    print(f"æœªçŸ¥é”™è¯¯: {e}")
```

### 5. è®°å½•å’Œç›‘æ§

```python
import logfire

logfire.configure()
logfire.instrument_pydantic_ai()

# Agent è¿è¡Œä¼šè‡ªåŠ¨è¿½è¸ªåˆ° Logfire
result = await agent.run('æç¤º')
```

## ğŸ“š ä¸‹ä¸€æ­¥

ç»§ç»­å­¦ä¹ ï¼š

1. [04_å·¥å…·ç³»ç»Ÿ.md](./04_å·¥å…·ç³»ç»Ÿ.md) - ç»™ Agent æ·»åŠ å·¥å…·èƒ½åŠ›
2. [05_ä¾èµ–æ³¨å…¥.md](./05_ä¾èµ–æ³¨å…¥.md) - æ·±å…¥ç†è§£ä¾èµ–æ³¨å…¥
3. [12_å¯è§‚æµ‹æ€§.md](./12_å¯è§‚æµ‹æ€§.md) - é›†æˆ Logfire ç›‘æ§

## ğŸ”— å‚è€ƒèµ„æº

- [å®˜æ–¹æ–‡æ¡£ - Agents](https://ai.pydantic.dev/agents/)
- [å®˜æ–¹æ–‡æ¡£ - Messages](https://ai.pydantic.dev/messages/)
- [API å‚è€ƒ - Agent](https://ai.pydantic.dev/api/agent/)
