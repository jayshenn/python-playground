# Pydantic AI æœ€ä½³å®è·µ

> æœ¬æ–‡æ¡£æ€»ç»“äº†æ„å»ºç”Ÿäº§çº§ Pydantic AI åº”ç”¨çš„æœ€ä½³å®è·µå’Œè®¾è®¡æ¨¡å¼ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. Agent ç»„ç»‡

#### å•ä¸€èŒè´£åŸåˆ™

```python
# âœ… å¥½çš„åšæ³•ï¼šæ¯ä¸ª Agent ä¸“æ³¨ä¸€ä¸ªé¢†åŸŸ
customer_support_agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœä»£è¡¨ã€‚'
)

data_analyst_agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚'
)

# âŒ é¿å…ï¼šä¸€ä¸ª Agent åšæ‰€æœ‰äº‹æƒ…
universal_agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ å¯ä»¥åšä»»ä½•äº‹æƒ…...'  # å¤ªå®½æ³›
)
```

#### Agent å·¥å‚æ¨¡å¼

```python
from typing import Literal

AgentType = Literal['support', 'sales', 'analyst']


def create_agent(agent_type: AgentType, deps_type=None) -> Agent:
    """åˆ›å»ºç‰¹å®šç±»å‹çš„ Agent"""
    configs = {
        'support': {
            'model': 'openai:gpt-4',
            'system_prompt': 'ä½ æ˜¯å®¢æœä»£è¡¨ã€‚',
            'temperature': 0.5
        },
        'sales': {
            'model': 'anthropic:claude-3-5-sonnet',
            'system_prompt': 'ä½ æ˜¯é”€å”®é¡¾é—®ã€‚',
            'temperature': 0.7
        },
        'analyst': {
            'model': 'openai:gpt-4',
            'system_prompt': 'ä½ æ˜¯æ•°æ®åˆ†æå¸ˆã€‚',
            'temperature': 0.3
        }
    }

    config = configs[agent_type]
    return Agent(
        config['model'],
        deps_type=deps_type,
        system_prompt=config['system_prompt'],
        model_settings=ModelSettings(temperature=config['temperature'])
    )
```

### 2. ä¾èµ–ç®¡ç†

#### ä½¿ç”¨ä¾èµ–æ³¨å…¥å®¹å™¨

```python
from dataclasses import dataclass
import httpx


@dataclass
class AppDependencies:
    """åº”ç”¨çº§ä¾èµ–å®¹å™¨"""
    database: Database
    cache: Cache
    http_client: httpx.AsyncClient
    config: dict
    logger: Logger


class DependencyContainer:
    """ä¾èµ–æ³¨å…¥å®¹å™¨"""

    def __init__(self):
        self._deps = None

    async def __aenter__(self):
        self._deps = AppDependencies(
            database=await Database.connect(),
            cache=await Redis.connect(),
            http_client=httpx.AsyncClient(),
            config=load_config(),
            logger=setup_logger()
        )
        return self._deps

    async def __aexit__(self, *args):
        await self._deps.database.close()
        await self._deps.cache.close()
        await self._deps.http_client.aclose()


# ä½¿ç”¨
async def main():
    async with DependencyContainer() as deps:
        result = await agent.run('æŸ¥è¯¢', deps=deps)
```

#### ç¯å¢ƒç‰¹å®šé…ç½®

```python
import os
from enum import Enum


class Environment(Enum):
    DEVELOPMENT = 'development'
    STAGING = 'staging'
    PRODUCTION = 'production'


def get_dependencies(env: Environment) -> AppDependencies:
    """æ ¹æ®ç¯å¢ƒè¿”å›ä¸åŒçš„ä¾èµ–"""
    if env == Environment.PRODUCTION:
        return AppDependencies(
            database=ProductionDB(),
            model='openai:gpt-4',
            api_timeout=30
        )
    elif env == Environment.STAGING:
        return AppDependencies(
            database=StagingDB(),
            model='openai:gpt-3.5-turbo',
            api_timeout=60
        )
    else:
        return AppDependencies(
            database=SQLiteDB(':memory:'),
            model='groq:llama3-70b-8192',  # å…è´¹
            api_timeout=120
        )


# ä½¿ç”¨
current_env = Environment(os.getenv('ENVIRONMENT', 'development'))
deps = get_dependencies(current_env)
```

## ğŸ’° æˆæœ¬ä¼˜åŒ–

### 1. æ™ºèƒ½æ¨¡å‹é€‰æ‹©

```python
from dataclasses import dataclass


@dataclass
class TaskComplexity:
    score: float  # 0-1

    @property
    def is_simple(self) -> bool:
        return self.score < 0.3

    @property
    def is_complex(self) -> bool:
        return self.score > 0.7


def select_model(complexity: TaskComplexity) -> str:
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    if complexity.is_simple:
        return 'openai:gpt-3.5-turbo'  # ä¾¿å®œå¿«é€Ÿ
    elif complexity.is_complex:
        return 'openai:gpt-4'  # é«˜è´¨é‡
    else:
        return 'anthropic:claude-3-5-sonnet'  # å¹³è¡¡


# ä½¿ç”¨
complexity = analyze_task_complexity(task)
model = select_model(complexity)
agent = Agent(model)
```

### 2. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib
import json


class AgentCache:
    """Agent å“åº”ç¼“å­˜"""

    def __init__(self, cache_backend):
        self.cache = cache_backend

    def _make_key(self, prompt: str, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{model}:{prompt}"
        return hashlib.md5(content.encode()).hexdigest()

    async def get_or_run(
        self,
        agent: Agent,
        prompt: str,
        deps=None,
        ttl: int = 3600
    ):
        """ä»ç¼“å­˜è·å–æˆ–è¿è¡Œ Agent"""
        cache_key = self._make_key(prompt, agent.model)

        # å°è¯•ä»ç¼“å­˜è·å–
        cached = await self.cache.get(cache_key)
        if cached:
            return json.loads(cached)

        # è¿è¡Œ Agent
        result = await agent.run(prompt, deps=deps)

        # ä¿å­˜åˆ°ç¼“å­˜
        await self.cache.set(
            cache_key,
            json.dumps(result.data),
            expire=ttl
        )

        return result.data
```

### 3. Token é™åˆ¶

```python
from pydantic_ai import UsageLimits

# è®¾ç½®åˆç†çš„é™åˆ¶
agent = Agent(
    'openai:gpt-4',
    usage_limits=UsageLimits(
        response_tokens_limit=2000,  # æ§åˆ¶è¾“å‡ºé•¿åº¦
        request_limit=5,             # é™åˆ¶å¾€è¿”æ¬¡æ•°
        tool_calls_limit=3           # é™åˆ¶å·¥å…·è°ƒç”¨
    )
)
```

## ğŸ”’ å®‰å…¨æ€§

### 1. è¾“å…¥éªŒè¯

```python
from pydantic import BaseModel, Field, field_validator


class UserInput(BaseModel):
    """éªŒè¯ç”¨æˆ·è¾“å…¥"""
    query: str = Field(..., min_length=1, max_length=1000)
    user_id: str = Field(..., pattern=r'^[a-zA-Z0-9-]+$')

    @field_validator('query')
    def sanitize_query(cls, v):
        # ç§»é™¤æ½œåœ¨å±é™©å­—ç¬¦
        dangerous_chars = ['<', '>', '&', '"', "'"]
        for char in dangerous_chars:
            v = v.replace(char, '')
        return v


# ä½¿ç”¨
try:
    validated_input = UserInput(
        query=user_query,
        user_id=user_id
    )
    result = await agent.run(validated_input.query)
except ValidationError as e:
    return {"error": "æ— æ•ˆè¾“å…¥"}
```

### 2. æ•æ„Ÿä¿¡æ¯ä¿æŠ¤

```python
import re


def redact_sensitive_info(text: str) -> str:
    """ç§»é™¤æ•æ„Ÿä¿¡æ¯"""
    # é‚®ç®±
    text = re.sub(
        r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        '[EMAIL]',
        text
    )

    # ç”µè¯
    text = re.sub(
        r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
        '[PHONE]',
        text
    )

    # ä¿¡ç”¨å¡
    text = re.sub(
        r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',
        '[CARD]',
        text
    )

    return text


# åœ¨è®°å½•æ—¥å¿—å‰ä½¿ç”¨
logfire.info('ç”¨æˆ·æŸ¥è¯¢', query=redact_sensitive_info(user_query))
```

### 3. æƒé™æ§åˆ¶

```python
@dataclass
class UserPermissions:
    can_delete: bool
    can_edit: bool
    can_view: bool


def create_agent_with_permissions(
    permissions: UserPermissions
) -> Agent:
    """æ ¹æ®æƒé™åˆ›å»º Agent"""
    agent = Agent('openai:gpt-4', deps_type=UserPermissions)

    # ä»…åœ¨æœ‰æƒé™æ—¶æ·»åŠ å·¥å…·
    if permissions.can_view:
        @agent.tool
        def view_data(ctx: RunContext[UserPermissions]) -> str:
            return "æŸ¥çœ‹æ•°æ®"

    if permissions.can_edit:
        @agent.tool
        def edit_data(ctx: RunContext[UserPermissions]) -> str:
            return "ç¼–è¾‘æ•°æ®"

    if permissions.can_delete:
        @agent.tool
        def delete_data(ctx: RunContext[UserPermissions]) -> str:
            return "åˆ é™¤æ•°æ®"

    return agent
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import AsyncMock


@pytest.fixture
def test_agent():
    """æµ‹è¯• Agent fixture"""
    return Agent('openai:gpt-4', deps_type=TestDeps)


@pytest.fixture
def test_deps():
    """æµ‹è¯•ä¾èµ– fixture"""
    return TestDeps(
        database=AsyncMock(),
        api_key='test-key'
    )


@pytest.mark.asyncio
async def test_agent_tool(test_agent, test_deps):
    """æµ‹è¯•å·¥å…·åŠŸèƒ½"""
    with test_agent.override(deps=test_deps):
        result = await test_agent.run('æµ‹è¯•æŸ¥è¯¢')

        # éªŒè¯å·¥å…·è¢«è°ƒç”¨
        test_deps.database.query.assert_called_once()

        # éªŒè¯è¾“å‡º
        assert 'expected' in result.data
```

### 2. é›†æˆæµ‹è¯•

```python
@pytest.mark.integration
async def test_full_workflow():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
    agent = Agent('openai:gpt-4')

    # ç¬¬ä¸€è½®
    result1 = await agent.run('å¼€å§‹å¯¹è¯')
    assert result1.data

    # ç¬¬äºŒè½® - ä½¿ç”¨å†å²
    result2 = await agent.run(
        'ç»§ç»­å¯¹è¯',
        message_history=result1.new_messages()
    )
    assert result2.data
```

### 3. ä½¿ç”¨ TestModel

```python
from pydantic_ai.models.test import TestModel


def test_agent_logic():
    """æµ‹è¯• Agent é€»è¾‘ï¼ˆä¸è°ƒç”¨çœŸå® LLMï¼‰"""
    test_model = TestModel(custom_result='æµ‹è¯•å“åº”')

    agent = Agent(test_model)

    result = agent.run_sync('ä»»ä½•æç¤º')

    assert result.data == 'æµ‹è¯•å“åº”'
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶å‘è¯·æ±‚

```python
import asyncio


async def process_batch(prompts: list[str], agent: Agent):
    """å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚"""
    tasks = [agent.run(prompt) for prompt in prompts]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # å¤„ç†ç»“æœå’Œé”™è¯¯
    successful = []
    failed = []

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            failed.append((prompts[i], result))
        else:
            successful.append(result)

    return successful, failed
```

### 2. æµå¼å¤„ç†å¤§å‹è¾“å‡º

```python
async def stream_large_content(prompt: str):
    """æµå¼å¤„ç†å¤§å‹å†…å®¹"""
    async with agent.run_stream(prompt) as stream:
        buffer = []

        async for chunk in stream.stream_text():
            buffer.append(chunk)

            # æ¯ 100 ä¸ªå­—ç¬¦å¤„ç†ä¸€æ¬¡
            if len(''.join(buffer)) >= 100:
                await process_chunk(''.join(buffer))
                buffer = []

        # å¤„ç†å‰©ä½™å†…å®¹
        if buffer:
            await process_chunk(''.join(buffer))
```

### 3. è¿æ¥æ± 

```python
import httpx


class HTTPClientPool:
    """HTTP å®¢æˆ·ç«¯æ± """

    def __init__(self, max_connections: int = 100):
        self._client = httpx.AsyncClient(
            limits=httpx.Limits(
                max_connections=max_connections,
                max_keepalive_connections=20
            )
        )

    async def __aenter__(self):
        return self._client

    async def __aexit__(self, *args):
        await self._client.aclose()


# ä½¿ç”¨
async with HTTPClientPool() as client:
    deps = AppDeps(http_client=client)
    # å¤ç”¨è¿æ¥
    results = await process_many_requests(agent, deps)
```

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### 1. å…³é”®æŒ‡æ ‡

```python
from dataclasses import dataclass
from datetime import datetime


@dataclass
class AgentMetrics:
    """Agent è¿è¡ŒæŒ‡æ ‡"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_tokens: int = 0
    total_cost: float = 0.0
    avg_latency: float = 0.0


class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics = AgentMetrics()

    async def record_run(self, result, duration: float):
        """è®°å½•è¿è¡ŒæŒ‡æ ‡"""
        self.metrics.total_requests += 1

        if result:
            self.metrics.successful_requests += 1
            self.metrics.total_tokens += result.usage().total_tokens
            self.metrics.total_cost += result.cost().total_cost or 0

        self.metrics.avg_latency = (
            (self.metrics.avg_latency * (self.metrics.total_requests - 1) +
             duration) / self.metrics.total_requests
        )

        # å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
        await self.send_metrics()
```

### 2. é”™è¯¯è¿½è¸ª

```python
from typing import Dict, List


class ErrorTracker:
    """é”™è¯¯è¿½è¸ªå™¨"""

    def __init__(self):
        self.errors: List[Dict] = []

    def track_error(
        self,
        error: Exception,
        context: dict
    ):
        """è¿½è¸ªé”™è¯¯"""
        self.errors.append({
            'error_type': type(error).__name__,
            'message': str(error),
            'context': context,
            'timestamp': datetime.now()
        })

        # å¦‚æœé”™è¯¯è¿‡å¤šï¼Œå‘é€å‘Šè­¦
        if len(self.errors) > 10:
            self.send_alert()
```

## ğŸ¯ æç¤ºå·¥ç¨‹

### 1. æ¸…æ™°çš„æŒ‡ä»¤

```python
# âœ… å¥½çš„æç¤º
agent = Agent(
    'openai:gpt-4',
    system_prompt='''
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Python ä»£ç å®¡æŸ¥å‘˜ã€‚

èŒè´£ï¼š
1. æ£€æŸ¥ä»£ç è´¨é‡
2. è¯†åˆ«æ½œåœ¨ bug
3. æä¾›æ”¹è¿›å»ºè®®

è¾“å‡ºæ ¼å¼ï¼š
- é—®é¢˜åˆ—è¡¨ï¼ˆæŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼‰
- æ¯ä¸ªé—®é¢˜åŒ…å«ï¼šä½ç½®ã€æè¿°ã€å»ºè®®ä¿®å¤
'''
)

# âŒ å·®çš„æç¤º
agent = Agent(
    'openai:gpt-4',
    system_prompt='ä½ æ˜¯ä»£ç å®¡æŸ¥å‘˜ï¼Œå®¡æŸ¥ä»£ç ã€‚'
)
```

### 2. ç¤ºä¾‹å¼•å¯¼

```python
@agent.system_prompt
def get_prompt(ctx: RunContext[None]) -> str:
    return '''
æå–åŸå¸‚ä¿¡æ¯ã€‚

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼šå·´é»æ˜¯æ³•å›½çš„é¦–éƒ½ï¼Œäººå£çº¦ 210 ä¸‡ã€‚
è¾“å‡ºï¼š{"city": "Paris", "country": "France", "population": 2100000}

è¾“å…¥ï¼šä¸œäº¬æ˜¯æ—¥æœ¬æœ€å¤§çš„åŸå¸‚ã€‚
è¾“å‡ºï¼š{"city": "Tokyo", "country": "Japan", "population": null}

ç°åœ¨å¤„ç†ç”¨æˆ·çš„è¾“å…¥ã€‚
'''
```

## ğŸ“š ä¸‹ä¸€æ­¥

ä½ å·²ç»å®Œæˆäº†æ‰€æœ‰æ ¸å¿ƒæ–‡æ¡£çš„å­¦ä¹ ï¼ç°åœ¨å¯ä»¥ï¼š

1. æŸ¥çœ‹ [15_å®æˆ˜æ¡ˆä¾‹.md](./15_å®æˆ˜æ¡ˆä¾‹.md) å­¦ä¹ å®Œæ•´åº”ç”¨æ¡ˆä¾‹
2. æµè§ˆ `examples/` ç›®å½•æŸ¥çœ‹ä»£ç ç¤ºä¾‹
3. å¼€å§‹æ„å»ºè‡ªå·±çš„ Agent åº”ç”¨

## ğŸ”— å‚è€ƒèµ„æº

- [å®˜æ–¹æ–‡æ¡£](https://ai.pydantic.dev/)
- [GitHub ä»“åº“](https://github.com/pydantic/pydantic-ai)
- [ç¤ºä¾‹ä»£ç ](https://github.com/pydantic/pydantic-ai/tree/main/examples)
